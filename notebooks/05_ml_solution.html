
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Exercises in Machine Learning &#8212; Materials Informatics 101</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Materials Informatics 101</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Materials Informatics 101
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../setup.html">
   Software Setup
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../exercises.html">
   Exercise Notebooks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="00_tabula-webplotdigitizer_assignment.html">
     Data Extraction and Management
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="01_python_assignment.html">
     Intro to Python and Jupyter Notebooks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="02_tidy_assignment.html">
     Intro to Data Wrangling and Tidy Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03_data_assignment.html">
     Programmatic Data Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04_vis_assignment.html">
     Visualization in Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="05_ml_assignment.html">
     Exercises in Machine Learning
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/05_ml_solution.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/zdelrosario/Materials Informatics 101"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/zdelrosario/Materials Informatics 101/issues/new?title=Issue%20on%20page%20%2Fnotebooks/05_ml_solution.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/zdelrosario/Materials Informatics 101/main?urlpath=tree/docs/notebooks/05_ml_solution.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-outcomes">
   Learning outcomes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#regression-helper-function">
   Regression Helper Function
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#underfitting-and-overfitting">
   Underfitting and Overfitting
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#working-with-models-in-grama">
     Working with models in Grama
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q1-evaluate-the-model-at-new-input-values">
     <strong>
      Q1
     </strong>
     : Evaluate the model at new input values
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-flexibility-and-underfitting">
     Model Flexibility and
     <em>
      Underfitting
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q2-fit-a-quadratic-model-to-the-data">
     <strong>
      Q2
     </strong>
     : Fit a quadratic model to the data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#noise-and-overfitting">
     Noise and
     <em>
      Overfitting
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q3-overfit-the-model">
     <strong>
      Q3
     </strong>
     : Overfit the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#balancing-overfitting-and-underfitting">
     Balancing Overfitting and Underfitting
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#quantifying-error-and-cross-validating">
   Quantifying Error and Cross-Validating
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-vs-test">
     Train vs Test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#avoiding-optimistic-estimates-cross-validation">
     Avoiding Optimistic Estimates: Cross-Validation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q4-override-the-defaults">
     <strong>
      Q4
     </strong>
     : Override the defaults
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#case-study-steel-fatigue-strength-prediction">
   Case Study: Steel Fatigue Strength Prediction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q5-fit-a-regression-to-predict-the-fatigue-strength">
     <strong>
      Q5
     </strong>
     : Fit a regression to predict the fatigue strength
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-different-kind-of-flexibility-featurization">
     A different kind of flexibility:
     <em>
      Featurization
     </em>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#q6-interpret-the-following-results">
     <strong>
      Q6
     </strong>
     : Interpret the following results
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusion">
     Conclusion
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#further-reading">
   Further Reading
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="exercises-in-machine-learning">
<h1>Exercises in Machine Learning<a class="headerlink" href="#exercises-in-machine-learning" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<p><em>Author</em>: Zach del Rosario</p>
<p>The <em>primary</em> purpose of this notebook is to help you <em>not get fooled by machine learning</em>! As Drew Conway notes, possessing hacking skills and substantive experience—but having no math or statistics background—puts one in the <a class="reference external" href="http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram">danger zone</a>. While we can’t possibly cover <em>everything</em> you need in a single workshop, this exercise will highlight some of the challenges of doing machine learning well. See the <em>Further Reading</em> section at the end for suggestions on learning more.</p>
<div class="section" id="learning-outcomes">
<h2>Learning outcomes<a class="headerlink" href="#learning-outcomes" title="Permalink to this headline">¶</a></h2>
<p>By working through this notebook, you will be able to:</p>
<ul class="simple">
<li><p>Use grama to work with models.</p></li>
<li><p>Understand the importance of <em>underfitting</em> and <em>overfitting</em>.</p></li>
<li><p>Use cross-validation to help avoid <em>underfitting</em> and <em>overfitting</em>.</p></li>
<li><p>State some example ways underfitting and overfitting show up studying a materials dataset.</p></li>
</ul>
<p>Tips:</p>
<ul class="simple">
<li><p>This exercise heavily uses the <a class="reference external" href="https://github.com/zdelrosario/py_grama">py-grama</a> package; you can find more info on the <a class="reference external" href="https://py-grama.readthedocs.io/en/latest/">documentation site</a>.</p></li>
<li><p>This exercise indirectly uses <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn</a>; you can find lots of useful info on this package on their <a class="reference external" href="https://scikit-learn.org/stable/documentation.html">documentation site</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setup</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">plotnine</span> <span class="k">as</span> <span class="nn">pt</span>
<span class="kn">import</span> <span class="nn">grama</span> <span class="k">as</span> <span class="nn">gr</span>

<span class="n">DF</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">Intention</span><span class="p">()</span>

<span class="c1"># Show all pandas columns</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_columns&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

<span class="c1"># For downloading data</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">requests</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Helper functions</span>
<span class="k">def</span> <span class="nf">add_noise</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">101</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Add noise to deterministic functions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">new_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">new_function</span>

<span class="c1"># Reference points for regression examples</span>
<span class="n">X_ref</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Reference models</span>
<span class="k">def</span> <span class="nf">fcn_1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="mf">0.3</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">fcn_2</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="p">(</span><span class="o">-</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mf">0.4</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">fcn_1_noisy</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_symbolic</span><span class="p">(</span><span class="n">add_noise</span><span class="p">(</span><span class="n">fcn_1</span><span class="p">))</span>
<span class="n">fcn_2_noisy</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">make_symbolic</span><span class="p">(</span><span class="n">add_noise</span><span class="p">(</span><span class="n">fcn_2</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">0.2</span><span class="p">))</span>

<span class="c1"># Package as a dataframe</span>
<span class="n">df_data</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">X_ref</span><span class="p">,</span>
    <span class="n">y_1</span><span class="o">=</span><span class="n">fcn_1_noisy</span><span class="p">(</span><span class="n">X_ref</span><span class="p">),</span>
    <span class="n">y_2</span><span class="o">=</span><span class="n">fcn_2_noisy</span><span class="p">(</span><span class="n">X_ref</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="regression-helper-function">
<h2>Regression Helper Function<a class="headerlink" href="#regression-helper-function" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p>This function will automate some steps so we can focus on high-level ideas, but I define it here in case you’d like to see the details.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## For partial evaluation</span>
<span class="kn">from</span> <span class="nn">toolz</span> <span class="kn">import</span> <span class="n">curry</span>
<span class="c1">## Model training tools</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="c1">## Encapsulate featurizer and regressor in one object</span>
<span class="k">class</span> <span class="nc">FunctionLM</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="n">runtime</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">regressor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">var</span> <span class="o">=</span> <span class="n">var</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="o">+</span> <span class="s2">&quot;_mean&quot;</span><span class="p">,</span> <span class="n">out</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">order</span> <span class="o">=</span> <span class="n">order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">runtime</span> <span class="o">=</span> <span class="n">runtime</span>

    <span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="c1">## Check invariant; model inputs must be subset of df columns</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Model function `</span><span class="si">{}</span><span class="s2">` var not a subset of given columns&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1">## Featurize</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
        <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">order</span><span class="p">)</span>
        <span class="n">X_feat</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1">## Predict</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_feat</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">)</span>

<span class="c1">## Fitting routine</span>
<span class="nd">@curry</span>
<span class="k">def</span> <span class="nf">fit_regression</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">var</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Fit a linear regression of specified order</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        df (DataFrame): Data for fitting</span>
<span class="sd">        var (iterable of str): Names of input variable (feature); must be column in df</span>
<span class="sd">        out (iterable of str): Name of output variable (response); must be column in df</span>
<span class="sd">        order (int): Polynomial order for fit</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;This simple helper can only handle one output.&quot;</span><span class="p">)</span>
    <span class="c1"># Featurize</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">var</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">order</span><span class="p">)</span>
    <span class="n">X_feat</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="c1"># Fit regression</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">out</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">lm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_feat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    
    <span class="c1"># Package</span>
    <span class="n">fun</span> <span class="o">=</span> <span class="n">FunctionLM</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">var</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="s2">&quot;Linear Model&quot;</span><span class="p">,</span> <span class="n">order</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">gr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">functions</span><span class="o">=</span><span class="p">[</span><span class="n">fun</span><span class="p">],</span> <span class="n">domain</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    
<span class="c1">## Create pipe-enabled regression utility</span>
<span class="n">ft_regression</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="n">fit_regression</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="underfitting-and-overfitting">
<h2>Underfitting and Overfitting<a class="headerlink" href="#underfitting-and-overfitting" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p>First we’ll cover some key ideas on simple cases. These are not ‘real’ data, but the simplicity of the examples will allow us to focus on concepts.</p>
<p>Here I generate some data from a simple polynomial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="c1"># Ground-truth data; no noise</span>
<span class="n">df_ex1</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">fcn_1</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">x</span><span class="p">))</span>
<span class="p">)</span>

<span class="c1"># Plot</span>
<span class="p">(</span>
    <span class="n">df_ex1</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_6_0.png" src="../_images/05_ml_solution_6_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781494511437)&gt;
</pre></div>
</div>
</div>
</div>
<p>We will fit a simple <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_regression">linear regression</a> to these data. To do this, we’ll use the linear regression helper <code class="docutils literal notranslate"><span class="pre">ft_regression()</span></code> (defined above). To start, we’ll assume that the data were generated from an underlying rule (a <em>model</em>) of the form</p>
<div class="math notranslate nohighlight">
\[y_{\text{mean}} = m x + b,\]</div>
<p>and attempt to <em>learn</em> the slope <span class="math notranslate nohighlight">\(m\)</span> and intercept <span class="math notranslate nohighlight">\(b\)</span> by <em>minimizing</em> the difference between the measured values <code class="docutils literal notranslate"><span class="pre">y</span></code> and the predicted values <code class="docutils literal notranslate"><span class="pre">y_mean</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="c1"># Fit the line</span>
<span class="n">md_line</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_ex1</span>
    <span class="o">&gt;&gt;</span> <span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Predict</span>
<span class="n">df_line_pred</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">md_line</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df_ex1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="p">(</span>
    <span class="n">df_line_pred</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y_mean&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_8_0.png" src="../_images/05_ml_solution_8_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781494832241)&gt;
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">ft_regression()</span></code> tool returns a <em>grama model</em>; let’s learn about this toolset.</p>
<div class="section" id="working-with-models-in-grama">
<h3>Working with models in Grama<a class="headerlink" href="#working-with-models-in-grama" title="Permalink to this headline">¶</a></h3>
<p>In addition to the data <em>transformation</em> tools we used in previous notebooks, grama provides a <em>model object</em> to simplify working with different forms of model. The <a class="reference external" href="https://py-grama.readthedocs.io/en/latest/">grama documentation</a> has more information, but let’s focus on the high-level details.</p>
<p>Like with a DataFrame, we can get a view of the model simply by printing it out:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit, run to show info on `md_line`</span>
<span class="n">md_line</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>model: None

  inputs:
    var_det:
      x: (unbounded)

    var_rand:


    copula:
      None

  functions:
      Linear Model: [&#39;x&#39;] -&gt; [&#39;y_mean&#39;]
</pre></div>
</div>
</div>
</div>
<p>The text above is a summary of what’s in the model. Based on this summary, we can see that it takes a single input <code class="docutils literal notranslate"><span class="pre">x</span></code> and maps it to a single output <code class="docutils literal notranslate"><span class="pre">y_mean</span></code>. This can be particularly useful for checking the “basic facts” about the model: what inputs does it require? What outputs does it provide?</p>
<p>Note that we fit a model to predict an output <code class="docutils literal notranslate"><span class="pre">y</span></code>, but our model provides <code class="docutils literal notranslate"><span class="pre">y_mean</span></code>. This renaming is deliberate; we’re providing a <em>predicted value</em>, not a <em>measured value</em>. Since our model is based on a <a class="reference external" href="https://en.wikipedia.org/wiki/Linear_regression#Interpretation">statistical mean</a>, the output gets the <code class="docutils literal notranslate"><span class="pre">_mean</span></code> suffix.</p>
<p>One of the most important uses of a fitted model is to predict unobserved output values. We can do this with a grama model by providing values for the desired inputs and <em>evaluating</em> the model.</p>
</div>
<div class="section" id="q1-evaluate-the-model-at-new-input-values">
<h3><strong>Q1</strong>: Evaluate the model at new input values<a class="headerlink" href="#q1-evaluate-the-model-at-new-input-values" title="Permalink to this headline">¶</a></h3>
<p>Use the function <code class="docutils literal notranslate"><span class="pre">gr.ev_df()</span></code> to evaluate the model <code class="docutils literal notranslate"><span class="pre">md_line</span></code> fitted above. Make use of the new set of input values <code class="docutils literal notranslate"><span class="pre">df_dense</span></code>. Answer the questions below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># TASK: Evaluate md_line at the df_dense input values.</span>
<span class="c1">###</span>

<span class="c1"># -- FINISH THE CODE BELOW -----</span>
<span class="n">df_dense</span> <span class="o">=</span> <span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>

<span class="n">df_evaluated</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">md_line</span>

    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df_dense</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># -- NO NEED TO EDIT BELOW HERE -----</span>
<span class="p">(</span>
    <span class="n">df_evaluated</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;Fit&quot;</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y_mean&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;source&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="n">df_ex1</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;Measured&quot;</span><span class="p">),</span>
        <span class="n">mapping</span><span class="o">=</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_14_0.png" src="../_images/05_ml_solution_14_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781494900493)&gt;
</pre></div>
</div>
</div>
</div>
<p><em>Observe</em></p>
<ul class="simple">
<li><p>How many points are measured? How many are fit? (Note: Don’t count by hand, try looking at the code!)</p>
<ul>
<li><p>There are 10 measured points, while there are 100 evaluated via the fit.</p></li>
</ul>
</li>
<li><p>Suppose we wanted to evaluate the quality of our fit. At how many locations could we evaluate the quality of the fit? Why?</p>
<ul>
<li><p>We could only evaluate the quality of the fit at 10 locations; the same ones where we have measurements of the function value.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="model-flexibility-and-underfitting">
<h3>Model Flexibility and <em>Underfitting</em><a class="headerlink" href="#model-flexibility-and-underfitting" title="Permalink to this headline">¶</a></h3>
<p>Note that we had to <em>assume</em> a model-form in order to do the fitting: <span class="math notranslate nohighlight">\(y_{\text{mean}} = m x + b\)</span>. From the figure above, we can see that the model is close to the true values, but obviously lacks the curvature of the true data-generating process.</p>
<p>This phenomenon—the failure of a model to capture behavior in the data—is called <em>underfitting</em>. To reduce underfitting, we need to make our model <em>more flexible</em>. For a linear regression, we can do this by <strong>increasing the order</strong> of the regression.</p>
</div>
<div class="section" id="q2-fit-a-quadratic-model-to-the-data">
<h3><strong>Q2</strong>: Fit a quadratic model to the data<a class="headerlink" href="#q2-fit-a-quadratic-model-to-the-data" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">ft_regression()</span></code> helper to fit a quadratic model (<code class="docutils literal notranslate"><span class="pre">order</span> <span class="pre">=</span> <span class="pre">2</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># TASK: Fit a quadratic model</span>
<span class="c1">###</span>

<span class="c1"># -- FINISH THE CODE BELOW -----</span>
<span class="c1"># Fit a quadratic</span>
<span class="n">md_quad</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_ex1</span>

    <span class="o">&gt;&gt;</span> <span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># -- NO NEED TO EDIT BELOW HERE -----</span>
<span class="c1"># Predict</span>
<span class="n">df_quad_pred</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">md_quad</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df_ex1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="p">(</span>
    <span class="n">df_quad_pred</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y_mean&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_18_0.png" src="../_images/05_ml_solution_18_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781494844073)&gt;
</pre></div>
</div>
</div>
</div>
<p>Here we can see the model fits the data <em>perfectly</em>. This <em>suggests</em> that we have successfully discovered the <em>exact</em> rule that generated these data, which in <em>this special case happens to be true</em>.</p>
<p>However, we will very rarely be able to fit the true function exactly. This is because real data tend to have <em>noise</em>, which corrupts the underlying function we are trying to learn.</p>
</div>
<div class="section" id="noise-and-overfitting">
<h3>Noise and <em>Overfitting</em><a class="headerlink" href="#noise-and-overfitting" title="Permalink to this headline">¶</a></h3>
<p>Below, I generate data from the same model, but add a little bit of noise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="c1"># Ground-truth data; now with noise</span>
<span class="n">df_ex2</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">fcn_1_noisy</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">x</span><span class="p">))</span>
<span class="p">)</span>

<span class="c1"># Plot</span>
<span class="p">(</span>
    <span class="n">df_ex2</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_21_0.png" src="../_images/05_ml_solution_21_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781495227705)&gt;
</pre></div>
</div>
</div>
</div>
<p>Let’s see what happens when we fit a quadratic to the noisy data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="p">(</span>
    <span class="n">df_ex2</span>
    <span class="o">&gt;&gt;</span> <span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df_ex2</span><span class="p">)</span>
    
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y_mean&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_23_0.png" src="../_images/05_ml_solution_23_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781495800885)&gt;
</pre></div>
</div>
</div>
</div>
<p>Here we can see that the fit is no longer perfect, despite coming from the “same” model. Since we already know that a quadratic can fit the underlying function perfectly, underfitting is not the issue here. Instead, the error is increased due to the noise in the data.</p>
<p><em>However</em>, we have not yet seen a case of <em>overfitting</em>. To see that phenomenon, let’s keep increasing the order of the model.</p>
</div>
<div class="section" id="q3-overfit-the-model">
<h3><strong>Q3</strong>: Overfit the model<a class="headerlink" href="#q3-overfit-the-model" title="Permalink to this headline">¶</a></h3>
<p>Increase the <code class="docutils literal notranslate"><span class="pre">order</span></code> of the regression until the model goes through every measured point. Does this seem like a reasonable model?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># TASK: Increase the order until the fit is perfect</span>
<span class="c1">###</span>

<span class="c1"># -- FINISH THE CODE BELOW -----</span>
<span class="p">(</span>
    <span class="n">df_ex2</span>
    <span class="o">&gt;&gt;</span> <span class="n">ft_regression</span><span class="p">(</span>
        <span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> 
        <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> 
        <span class="n">order</span><span class="o">=</span><span class="mi">2</span> <span class="c1"># TODO: Increase the order until the fit is perfect</span>
    <span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)))</span>
    
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y_mean&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span>
        <span class="n">data</span><span class="o">=</span><span class="n">df_ex2</span><span class="p">,</span>
        <span class="n">mapping</span><span class="o">=</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_26_0.png" src="../_images/05_ml_solution_26_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781495922157)&gt;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="balancing-overfitting-and-underfitting">
<h3>Balancing Overfitting and Underfitting<a class="headerlink" href="#balancing-overfitting-and-underfitting" title="Permalink to this headline">¶</a></h3>
<p>To help illustrate, let’s look at one more synthetic example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="c1"># More complicated function with noise</span>
<span class="n">df_ex3</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">fcn_2_noisy</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">x</span><span class="p">))</span>
<span class="p">)</span>

<span class="p">(</span>
    <span class="n">df_ex3</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_28_0.png" src="../_images/05_ml_solution_28_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781494901005)&gt;
</pre></div>
</div>
</div>
</div>
<p>Here we can see a somewhat complicated function that is quite corrupted by noise. Below, I’m going to fit a number of polynomial models of different orders. In practice, we would like to <em>make a decision</em> about what polynomial order to use. A sensible choice would be to pick the order that minimizes the error—let’s see which model accomplishes this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># -- DEMONSTRATION CODE, NO NEED TO EDIT -----</span>
<span class="c1"># Fit on many different orders</span>
<span class="n">df_train_err</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_test_err</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Fit the model</span>
    <span class="n">md_tmp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df_ex3</span>
        <span class="o">&gt;&gt;</span> <span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Evaluate model on training data</span>
    <span class="n">df_tmp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">md_tmp</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df_ex3</span><span class="p">)</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">df_train_err</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">df_train_err</span><span class="p">,</span> <span class="n">df_tmp</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># Evaluate model on test data</span>
    <span class="n">df_tmp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">gr</span><span class="o">.</span><span class="n">df_make</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">fcn_2</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">x</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_md</span><span class="p">(</span><span class="n">md</span><span class="o">=</span><span class="n">md_tmp</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">df_test_err</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">df_test_err</span><span class="p">,</span> <span class="n">df_tmp</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Visualize a few cases</span>
<span class="p">(</span>
    <span class="n">df_train_err</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_filter</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">var_in</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">order</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">]))</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y_mean&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;factor(order)&quot;</span><span class="p">),</span> <span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_point</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_ex3</span><span class="p">,</span> <span class="n">mapping</span><span class="o">=</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_30_0.png" src="../_images/05_ml_solution_30_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781495238805)&gt;
</pre></div>
</div>
</div>
</div>
<p>Here I’ve selected just a few of the models to plot. We can see</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">=</span> <span class="pre">1</span></code> case is <strong>underfit</strong>, like we saw in the example above</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">=</span> <span class="pre">9</span></code> case curves tortuously to go through many points; this is an example of <strong>overfitting</strong></p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">=</span> <span class="pre">3</span></code> case is not perfect, but tends to balance between underfitting and overfitting. This is a well-fit model.</p></li>
</ul>
<p>More generally, <em>overfitting</em> is when the model fits to spurrious patterns in the data; essentially, we are fitting to noise, rather than signal. We would like to detect and avoid overfitting in practice! While we can see above some suspicious behavior based on the fitted curves, we might like a <em>quantitative</em> way to compare models; in particular, once we have multiple inputs we won’t be able to create simple <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">vs</span> <span class="pre">x</span></code> plots like we do above.</p>
<p>Additionally, there’s a <em>subtle</em> issue that we’ll run into when it comes to evaluating the accuracy of a model: The <code class="docutils literal notranslate"><span class="pre">Order</span> <span class="pre">=</span> <span class="pre">9</span></code> case <em>clearly</em> looks unstable and untrustworthy, but note that the model is <em>perfect</em> at the points where we have measured output values. This is going to present some issues that we’ll see below:</p>
</div>
</div>
<div class="section" id="quantifying-error-and-cross-validating">
<h2>Quantifying Error and Cross-Validating<a class="headerlink" href="#quantifying-error-and-cross-validating" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p>There are a wide variety of ways to quantify the accuracy of a model: The code below computes three example metrics.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="p">(</span>
    <span class="n">df_train_err</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_group_by</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">order</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_summarize</span><span class="p">(</span>
        <span class="n">mse</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="n">DF</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
        <span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="n">DF</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
        <span class="n">rsq</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">rsq</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="n">DF</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order</th>
      <th>mse</th>
      <th>ndme</th>
      <th>rsq</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>4.668461e-01</td>
      <td>0.732299</td>
      <td>0.463738</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>4.050477e-01</td>
      <td>0.635361</td>
      <td>0.596316</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1.577792e-01</td>
      <td>0.247494</td>
      <td>0.938747</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1.329599e-01</td>
      <td>0.208562</td>
      <td>0.956502</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1.326107e-01</td>
      <td>0.208014</td>
      <td>0.956730</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>9.853369e-02</td>
      <td>0.154561</td>
      <td>0.976111</td>
    </tr>
    <tr>
      <th>6</th>
      <td>7</td>
      <td>6.828802e-02</td>
      <td>0.107117</td>
      <td>0.988526</td>
    </tr>
    <tr>
      <th>7</th>
      <td>8</td>
      <td>6.490153e-04</td>
      <td>0.001018</td>
      <td>0.999999</td>
    </tr>
    <tr>
      <th>8</th>
      <td>9</td>
      <td>4.681930e-15</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mse</span></code> is <a class="reference external" href="https://en.wikipedia.org/wiki/Mean_squared_error">mean-squared error</a>, a common error metric often used in the machine learning community. Smaller values are more accurate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ndme</span></code> stands for <em>non-dimensional model error</em>. As the name implies, this quantity is dimensionless, and takes a value of <code class="docutils literal notranslate"><span class="pre">0</span></code> when the model is perfect, and a value of <code class="docutils literal notranslate"><span class="pre">1</span></code> (sometimes higher) when the model is uninformative. This metric is not terribly common, but it is very <em>useful</em> as a dimensionless metric for error.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rsq</span></code> is short for <span class="math notranslate nohighlight">\(R^2\)</span> (r-squared), also called the <a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_determination">coefficient of determination</a>, a common <em>goodness of fit</em> metric used in the statistics community. Higher values are more accurate, with <span class="math notranslate nohighlight">\(R^2 = 1\)</span> indicating a perfect fit.</p></li>
</ul>
<div class="section" id="train-vs-test">
<h3>Train vs Test<a class="headerlink" href="#train-vs-test" title="Permalink to this headline">¶</a></h3>
<p>Remember above how the <code class="docutils literal notranslate"><span class="pre">order</span> <span class="pre">=</span> <span class="pre">9</span></code> model looked untrustworthy, but went through all of our observed data points? Let’s quantify the error both on the available data (the <code class="docutils literal notranslate"><span class="pre">train</span></code> data), but check the model’s behavior on an independent set of observations (the <code class="docutils literal notranslate"><span class="pre">test</span></code> data). The code below plots error estimated using these two different sets of data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="p">(</span>
    <span class="n">df_train_err</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_bind_rows</span><span class="p">(</span>
        <span class="n">df_test_err</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">source</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_group_by</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">order</span><span class="p">,</span> <span class="n">DF</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_summarize</span><span class="p">(</span><span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">(</span><span class="n">DF</span><span class="o">.</span><span class="n">y_mean</span><span class="p">,</span> <span class="n">DF</span><span class="o">.</span><span class="n">y</span><span class="p">))</span>
    
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="s2">&quot;ndme&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_line</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">linetype</span><span class="o">=</span><span class="s2">&quot;source&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">scale_y_log10</span><span class="p">()</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">labs</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="s2">&quot;Polynomial Order&quot;</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="s2">&quot;NDME&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Warning: divide by zero encountered in log10
</pre></div>
</div>
<img alt="../_images/05_ml_solution_36_1.png" src="../_images/05_ml_solution_36_1.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781496221785)&gt;
</pre></div>
</div>
</div>
</div>
<p>Here we can see the <code class="docutils literal notranslate"><span class="pre">train</span></code> and <code class="docutils literal notranslate"><span class="pre">test</span></code> error values <em>greatly diverge</em>. This is <em>highly problematic</em> for two interrelated reasons:</p>
<ol class="simple">
<li><p>In practice, we would only have access to the <code class="docutils literal notranslate"><span class="pre">train</span></code> curve, as the <code class="docutils literal notranslate"><span class="pre">test</span></code> curve relies on extra data (that we don’t have).</p></li>
<li><p>If we were to make a decision about <code class="docutils literal notranslate"><span class="pre">Polynomial</span> <span class="pre">Order</span></code> based on the <code class="docutils literal notranslate"><span class="pre">train</span></code> curve, we would choose a much higher order than what would minimize the NDME in the <code class="docutils literal notranslate"><span class="pre">True</span></code> case.</p></li>
</ol>
<p>The underlying reason for the poor error estimate here is that <em>we are using the same data to both train and test the model</em>. We can improve our estimates for the error through various techniques; below, we will use the technique of <em>cross-validation</em>.</p>
</div>
<div class="section" id="avoiding-optimistic-estimates-cross-validation">
<h3>Avoiding Optimistic Estimates: Cross-Validation<a class="headerlink" href="#avoiding-optimistic-estimates-cross-validation" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">Cross-validation</a> is one technique for estimating the error in a way that avoids the “optimism” we saw above. For the variant <em>k-fold cross-validation</em> (k-fold CV), we split all our data into <em>folds</em>, and use these to build <em>training</em> and <em>test</em> sets. Generally:</p>
<ul class="simple">
<li><p><em>Training</em> data are used to fit a model</p></li>
<li><p><em>Test</em> data are used to evaluate a model</p></li>
</ul>
<p><img alt="CV schematic" src="https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg" /></p>
<p>(Schematic for k-fold CV. Fabian Flock, via Wikimedia)</p>
<p>In each of our <span class="math notranslate nohighlight">\(k\)</span> iterations, we <em>do not allow</em> the model to see a test fold (<code class="docutils literal notranslate"><span class="pre">Test</span> <span class="pre">data</span></code> above) during training, and fit the model only on the remaining data (<code class="docutils literal notranslate"><span class="pre">Training</span> <span class="pre">data</span></code> above). After training, we compute our chosen error metric on the test fold. Finally, we repeat this process on each of the <span class="math notranslate nohighlight">\(k\)</span> chosen folds. This gives us a set of less optimistic estimates for the error, which we can summarize e.g. as a mean CV error.</p>
<p>This procedure is implemented in the grama function <code class="docutils literal notranslate"><span class="pre">tf_kfolds()</span></code>, as demonstrated below. Note that <code class="docutils literal notranslate"><span class="pre">tf_kfolds()</span></code> takes in a dataset to use for k-fold cross validation, as well as a <em>fitting procedure</em> that we will use for each iteration. The routine also provides some reasonable default values for the number of folds <code class="docutils literal notranslate"><span class="pre">k</span></code> and the error metrics to compute. We can override these by providing keyword arguments (as you’ll do below).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="p">(</span>
    <span class="n">df_ex3</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_kfolds</span><span class="p">(</span>
        <span class="n">ft</span><span class="o">=</span><span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="mi">9</span><span class="p">),</span>
<span class="c1">#         summaries=dict(mse=gr.mse), # Uncomment to override defaults</span>
<span class="c1">#         k=3,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>... tran_kfolds is using default k=5
... tran_kfolds is using default summaries mse and rsq
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mse_y</th>
      <th>rsq_y</th>
      <th>_kfold</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.108525</td>
      <td>-845.309197</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>171.743484</td>
      <td>-1999.093619</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>49.593784</td>
      <td>-37.624744</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.082404</td>
      <td>-1.476301</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.724433</td>
      <td>-15.585805</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note that the k-fold CV estimated <code class="docutils literal notranslate"><span class="pre">rsq_y</span></code> values are <em>abysmal</em>; they take negative values, which indicates that the model performance is quite bad.</p>
<p>One powerful use of k-fold CV is to do a <em>hyperparameter study</em>: In our case, we’ll study how the model accuracy changes as we sweep over the polynomial order.</p>
</div>
<div class="section" id="q4-override-the-defaults">
<h3><strong>Q4</strong>: Override the defaults<a class="headerlink" href="#q4-override-the-defaults" title="Permalink to this headline">¶</a></h3>
<p>Complete the code below by overriding the default settings for <code class="docutils literal notranslate"><span class="pre">tf_kfolds()</span></code>. Provide an estimate of the non-dimensional model error (<code class="docutils literal notranslate"><span class="pre">gr.ndme</span></code>). You can also try changing the value of <code class="docutils literal notranslate"><span class="pre">k</span></code> to see how the results change.</p>
<p>Answer the questions under <em>Observations</em> below.</p>
<p><em>Hint:</em> You may find that the code throws errors for larger values of <code class="docutils literal notranslate"><span class="pre">k</span></code>. Think about how many data points you have available in <code class="docutils literal notranslate"><span class="pre">df_ex3</span></code>. How many folds can you split the data into while having more than just one point in each fold?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># TASK: Increase the order until the fit is perfect</span>
<span class="c1">###</span>

<span class="c1"># -- FINISH THE CODE BELOW -----</span>
<span class="c1"># Fit on many different orders</span>
<span class="n">df_kfolds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="c1"># Iterate over a selection of polynomial orders</span>
<span class="k">for</span> <span class="n">order</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Evaluate model with k-fold CV</span>
    <span class="n">df_tmp</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">df_ex3</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_kfolds</span><span class="p">(</span>
            <span class="c1"># Use the desired polynomial order for this iteration</span>
            <span class="n">ft</span><span class="o">=</span><span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;x&quot;</span><span class="p">],</span> <span class="n">out</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">),</span>

            <span class="n">summaries</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">),</span>
            <span class="n">seed</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span>
            <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Record the order used in fitting</span>
        <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">order</span><span class="o">=</span><span class="n">order</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Record the results for this polynomial order</span>
    <span class="n">df_kfolds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">df_kfolds</span><span class="p">,</span> <span class="n">df_tmp</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    
<span class="c1"># Visualize</span>
<span class="p">(</span>
    <span class="n">df_kfolds</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="s2">&quot;ndme_y&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_boxplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;order&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">scale_x_continuous</span><span class="p">(</span><span class="n">breaks</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">scale_y_log10</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_43_0.png" src="../_images/05_ml_solution_43_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781496481393)&gt;
</pre></div>
</div>
</div>
</div>
<p><em>Observe</em></p>
<ul class="simple">
<li><p>How much do the results change as you change <code class="docutils literal notranslate"><span class="pre">k</span></code>?</p>
<ul>
<li><p>I find that the lowest-error order (<code class="docutils literal notranslate"><span class="pre">3</span></code>) is more “clear cut” for <code class="docutils literal notranslate"><span class="pre">k=2</span></code> and <code class="docutils literal notranslate"><span class="pre">k=3</span></code>, though the minimum error tends to be around order <code class="docutils literal notranslate"><span class="pre">3</span></code> or <code class="docutils literal notranslate"><span class="pre">4</span></code> for other values of <code class="docutils literal notranslate"><span class="pre">k</span></code> too.</p></li>
</ul>
</li>
<li><p>What polynomial <code class="docutils literal notranslate"><span class="pre">order</span></code> would you select, <em>based on the k-fold CV results</em>? Why?</p>
<ul>
<li><p>Either <code class="docutils literal notranslate"><span class="pre">order=3</span></code> or <code class="docutils literal notranslate"><span class="pre">order=4</span></code> would be reasonable, based on these results. I picked <code class="docutils literal notranslate"><span class="pre">order=3</span></code>, as the error is a bit more consistent for this choice (in variability, and across values of <code class="docutils literal notranslate"><span class="pre">k</span></code>).</p></li>
</ul>
</li>
<li><p>Inspect the function definition of <code class="docutils literal notranslate"><span class="pre">fcn_2</span></code> at the top of this notebook. What is the <em>true</em> polynomial order of the underlying function?</p>
<ul>
<li><p>The <em>true</em> order is <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p></li>
</ul>
</li>
</ul>
<p>Here we have just one tunable knob (polynomial order) that defines our model. More generally, these kinds of user-selected quantities are called <a class="reference external" href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</a>. Cross-validation and related techniques are key to <em>tuning hyperparameters</em>, and generally making choices about what sort of model we ought to choose.</p>
<div class="admonition-terminology-alert admonition">
<p class="admonition-title">Terminology Alert</p>
<p>Across various communities, the terms “train”, “test”, and “validation” data are used somewhat inconsistently. The term “train” is used most consistently: The training data is a subset of data used to fit the model. However different authors use the terms “test” and “validation” interchangeably.</p>
<p>What’s truly important is that you keep in mind the <strong>purpose</strong> of data subsets: Which subset is being used to fit the model? (Train) Which subset is being used to estimate error for hyperparameter tuning? (Test or Validation) Do you have a third disjoint subset to give an unbiased error estimate? (Validation or Test). For more information, see the relevant <a class="reference external" href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">Wikipedia article</a>.</p>
</div>
</div>
</div>
<div class="section" id="case-study-steel-fatigue-strength-prediction">
<h2>Case Study: Steel Fatigue Strength Prediction<a class="headerlink" href="#case-study-steel-fatigue-strength-prediction" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p>So far, we’ve looked at fairly artificial modeling problems. To help illustrate these fitting and cross-validation ideas in a real materials problem, let’s look at predicting the fatigue strength of steel alloys.</p>
<p>The data for this case study come from <a class="reference external" href="https://link.springer.com/article/10.1186/2193-9772-3-8">Agrawal et al. (2014) <em>IMMI</em></a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Filename for local data</span>
<span class="n">filename_data</span> <span class="o">=</span> <span class="s2">&quot;./data/agrawal_data.csv&quot;</span>

<span class="c1"># The following code downloads the data, or (after downloaded)</span>
<span class="c1"># loads the data from a cached CSV on your machine</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename_data</span><span class="p">):</span>
    <span class="c1"># Make request for data</span>
    <span class="n">url_data</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/zdelrosario/mi101/main/mi101/data/agrawal_data.csv&quot;</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url_data</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">filename_data</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;   Alloy data downloaded from public GitHub file&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Note data already exists</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;    Alloy data loaded locally&quot;</span><span class="p">)</span>
    
<span class="c1"># Read the data into memory</span>
<span class="n">df_raw</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filename_data</span><span class="p">)</span>

<span class="c1"># Drop the index columns</span>
<span class="n">df_fatigue_data</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_raw</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_drop</span><span class="p">(</span><span class="s2">&quot;Unnamed: 0&quot;</span><span class="p">,</span> <span class="s2">&quot;Sample Number&quot;</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_select</span><span class="p">(</span><span class="s2">&quot;Fatigue Strength&quot;</span><span class="p">,</span> <span class="s2">&quot;chemical_formula&quot;</span><span class="p">,</span> <span class="n">gr</span><span class="o">.</span><span class="n">everything</span><span class="p">())</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    Alloy data loaded locally
</pre></div>
</div>
</div>
</div>
<p>As always, we start by doing basic checks on the dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit</span>
<span class="n">df_fatigue_data</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fatigue Strength</th>
      <th>chemical_formula</th>
      <th>Area Proportion of Inclusions Occurring in Discontinuous Array</th>
      <th>Quenching Media Temperature (for Carburization)</th>
      <th>Diffusion time</th>
      <th>Through Hardening Time</th>
      <th>Cooling Rate for Tempering</th>
      <th>Reduction Ratio (Ingot to Bar)</th>
      <th>Normalizing Temperature</th>
      <th>Diffusion Temperature</th>
      <th>Carburization Time</th>
      <th>Cooling Rate for Through Hardening</th>
      <th>Area Proportion of Inclusions Deformed by Plastic Work</th>
      <th>Tempering Temperature</th>
      <th>Area Proportion of Isolated Inclusions</th>
      <th>Tempering Time</th>
      <th>Carburization Temperature</th>
      <th>Through Hardening Temperature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>451.0</td>
      <td>Fe0.9759C0.004Mn0.0156Cu0.0005Si0.0022P0.00011...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>530.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.02</td>
      <td>550.0</td>
      <td>0.01</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>631.0</td>
      <td>Fe0.97088C0.004Mn0.0074Cu0.001Si0.0025P0.00014...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>510.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.04</td>
      <td>550.0</td>
      <td>0.03</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>406.0</td>
      <td>Fe0.97588C0.0038Mn0.0152Cu0.0007Si0.0027P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>610.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.03</td>
      <td>600.0</td>
      <td>0.01</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>433.0</td>
      <td>Fe0.98575C0.0037Mn0.0072Cu0.0002Si0.0024P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>1740.0</td>
      <td>865.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>24.0</td>
      <td>0.10</td>
      <td>550.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>865.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>385.0</td>
      <td>Fe0.97588C0.0038Mn0.0152Cu0.0007Si0.0027P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>610.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.03</td>
      <td>650.0</td>
      <td>0.01</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>432</th>
      <td>490.0</td>
      <td>Fe0.97201C0.0041Mn0.0077Cu0.0005Si0.0024P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>530.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.03</td>
      <td>650.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
    <tr>
      <th>433</th>
      <td>463.0</td>
      <td>Fe0.98354C0.0048Mn0.0075Si0.0025P0.00024S0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>1740.0</td>
      <td>845.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>24.0</td>
      <td>0.08</td>
      <td>600.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>434</th>
      <td>592.0</td>
      <td>Fe0.97476C0.0035Mn0.007Cu0.0002Si0.0025P0.0002...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>820.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.10</td>
      <td>550.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
    <tr>
      <th>435</th>
      <td>245.0</td>
      <td>Fe0.98918C0.0026Mn0.0045Cu0.0003Si0.0022P0.000...</td>
      <td>0.02</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>825.0</td>
      <td>885.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.06</td>
      <td>30.0</td>
      <td>0.02</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>436</th>
      <td>526.0</td>
      <td>Fe0.97284C0.0036Mn0.0081Cu0.0008Si0.0023P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>530.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.02</td>
      <td>550.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
  </tbody>
</table>
<p>437 rows × 18 columns</p>
</div></div></div>
</div>
<p>We have the outcome column that we seek to model (<code class="docutils literal notranslate"><span class="pre">Fatigue</span> <span class="pre">Strength</span></code>, at <span class="math notranslate nohighlight">\(10^7\)</span> cycles), the chemical composition of the alloy in string-form, and a <em>large</em> number of processing characteristics.</p>
<p>We can inspect a histogram of the fatigue strength to get a sense for the variation in the quantity we seek to model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">df_fatigue_data</span>
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;Fatigue Strength&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_histogram</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">theme_minimal</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_52_0.png" src="../_images/05_ml_solution_52_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781496609121)&gt;
</pre></div>
</div>
</div>
</div>
<p>The fatigue strength is <em>highly variable</em>, with a large bulk around <code class="docutils literal notranslate"><span class="pre">500</span></code>, but values as low as <code class="docutils literal notranslate"><span class="pre">250</span></code> and over <code class="docutils literal notranslate"><span class="pre">1000</span></code> as well.</p>
<p><em>NB</em> I had difficulty finding the units for the reported Fatigue Strength in the <a class="reference external" href="https://link.springer.com/article/10.1186/2193-9772-3-8#Abs1">original publication</a>. Presumably these values are given in <code class="docutils literal notranslate"><span class="pre">MPa</span></code>.</p>
<p>This dataset has <em>many</em> columns; for modeling our first job should be to sort out what we want to predict, and which columns (<em>features</em>) we should use to predict that quantity. Our linear regression implementation can only handle <em>numeric</em> columns, so let’s inspect the datatypes to see which features our model can handle:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_fatigue_data</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fatigue Strength                                                  float64
chemical_formula                                                   object
Area Proportion of Inclusions Occurring in Discontinuous Array    float64
Quenching Media Temperature (for Carburization)                   float64
Diffusion time                                                    float64
Through Hardening Time                                            float64
Cooling Rate for Tempering                                        float64
Reduction Ratio (Ingot to Bar)                                    float64
Normalizing Temperature                                           float64
Diffusion Temperature                                             float64
Carburization Time                                                float64
Cooling Rate for Through Hardening                                float64
Area Proportion of Inclusions Deformed by Plastic Work            float64
Tempering Temperature                                             float64
Area Proportion of Isolated Inclusions                            float64
Tempering Time                                                    float64
Carburization Temperature                                         float64
Through Hardening Temperature                                     float64
dtype: object
</pre></div>
</div>
</div>
</div>
<p>The majority of the columns are numeric, <em>except</em> for the <code class="docutils literal notranslate"><span class="pre">chemical_formula</span></code>. To start, let’s try modeling the strength without any composition information. The following code creates python lists to target the desired response (<code class="docutils literal notranslate"><span class="pre">col_response</span></code>) and non-composition features (<code class="docutils literal notranslate"><span class="pre">col_features</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: Obtain column names for the response and features</span>
<span class="n">col_response</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Fatigue Strength&quot;</span><span class="p">]</span>
<span class="n">col_processing</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_data</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_drop</span><span class="p">(</span><span class="n">col_response</span><span class="p">,</span> <span class="s2">&quot;chemical_formula&quot;</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">columns</span>

<span class="n">col_processing</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;Area Proportion of Inclusions Occurring in Discontinuous Array&#39;,
       &#39;Quenching Media Temperature (for Carburization)&#39;, &#39;Diffusion time&#39;,
       &#39;Through Hardening Time&#39;, &#39;Cooling Rate for Tempering&#39;,
       &#39;Reduction Ratio (Ingot to Bar)&#39;, &#39;Normalizing Temperature&#39;,
       &#39;Diffusion Temperature&#39;, &#39;Carburization Time&#39;,
       &#39;Cooling Rate for Through Hardening&#39;,
       &#39;Area Proportion of Inclusions Deformed by Plastic Work&#39;,
       &#39;Tempering Temperature&#39;, &#39;Area Proportion of Isolated Inclusions&#39;,
       &#39;Tempering Time&#39;, &#39;Carburization Temperature&#39;,
       &#39;Through Hardening Temperature&#39;],
      dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="section" id="q5-fit-a-regression-to-predict-the-fatigue-strength">
<h3><strong>Q5</strong>: Fit a regression to predict the fatigue strength<a class="headerlink" href="#q5-fit-a-regression-to-predict-the-fatigue-strength" title="Permalink to this headline">¶</a></h3>
<p>Use the <code class="docutils literal notranslate"><span class="pre">ft_regression()</span></code> helper to fit a regression (with 1st order) to predict the fatigue strength.</p>
<p>Answer the questions under <em>Observations</em> below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">###</span>
<span class="c1"># TASK: Complete the code below to fit a 1st order regression</span>
<span class="c1">#       use col_features as the inputs (var)</span>
<span class="c1">#       use col_response as the output (out)</span>
<span class="c1">###</span>

<span class="c1"># -- FINISH THE CODE BELOW -----</span>
<span class="c1">## TODO: Fit a model here</span>
<span class="n">md_fatigue</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_data</span>
    <span class="o">&gt;&gt;</span> <span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="n">col_processing</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">col_response</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># -- NO NEED TO EDIT BELOW -----</span>
<span class="p">(</span>
    <span class="n">md_fatigue</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">ev_df</span><span class="p">(</span><span class="n">df_fatigue_data</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_summarize</span><span class="p">(</span>
        <span class="n">rmse</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">rmse</span><span class="p">(</span><span class="n">DF</span><span class="p">[</span><span class="s2">&quot;Fatigue Strength_mean&quot;</span><span class="p">],</span> <span class="n">DF</span><span class="p">[</span><span class="s2">&quot;Fatigue Strength&quot;</span><span class="p">]),</span>
        <span class="n">rsq</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">rsq</span><span class="p">(</span><span class="n">DF</span><span class="p">[</span><span class="s2">&quot;Fatigue Strength_mean&quot;</span><span class="p">],</span> <span class="n">DF</span><span class="p">[</span><span class="s2">&quot;Fatigue Strength&quot;</span><span class="p">]),</span>
        <span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">(</span><span class="n">DF</span><span class="p">[</span><span class="s2">&quot;Fatigue Strength_mean&quot;</span><span class="p">],</span> <span class="n">DF</span><span class="p">[</span><span class="s2">&quot;Fatigue Strength&quot;</span><span class="p">]),</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rmse</th>
      <th>rsq</th>
      <th>ndme</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>50.084447</td>
      <td>0.927817</td>
      <td>0.268669</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><em>Observations</em></p>
<ul class="simple">
<li><p>How accurate is your model?</p>
<ul>
<li><p>In terms of <em>training</em> error, the model is quite accurate. The <code class="docutils literal notranslate"><span class="pre">rmse</span></code> value is on the order of <code class="docutils literal notranslate"><span class="pre">50</span></code>; remember that we saw a bulk of values around <code class="docutils literal notranslate"><span class="pre">500</span></code> with variation between <code class="docutils literal notranslate"><span class="pre">[200,</span> <span class="pre">1000]</span></code>. Compared to the range of the data, we’re doing quite well!</p></li>
</ul>
</li>
<li><p>Is the model <em>flexible</em> enough to accurately capture the behavior in the data?</p>
<ul>
<li><p>Yes, in absolute terms the model error is small, indicating the model is flexible enough to capture behavior.</p></li>
</ul>
</li>
<li><p>Is the way we’ve estimated error here <em>appropriate</em> for making decisions about the model’s design? E.g. could we reasonably tune the polynomial order with this error estimate?</p>
<ul>
<li><p>Nope! We’re just looking at <em>test</em> error right now. We should use a procedure like k-fold CV if we want to tune hyperparameters.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="a-different-kind-of-flexibility-featurization">
<h3>A different kind of flexibility: <em>Featurization</em><a class="headerlink" href="#a-different-kind-of-flexibility-featurization" title="Permalink to this headline">¶</a></h3>
<p>What if we wanted to use the chemical composition as a feature? We can’t use the string as it is (what would <span class="math notranslate nohighlight">\(m \times \text{string}\)</span> <em>mean</em>?). Instead, we can go through a process of <em>featurization</em> (also called <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_engineering">feature engineering</a>) to create usable numeric columns that our model can use as inputs.</p>
<p>Featurization is a <em>big</em> topic, one that is inherently problem-specific. To get us started, we’re going to use a featurization scheme by <a class="reference external" href="https://www.nature.com/articles/npjcompumats201628?report=reader">Ward et al. (2016)</a>, as-implemented in the <a class="reference external" href="https://hackingmaterials.lbl.gov/matminer/">matminer</a> python package.</p>
<p>The following code loads a grama interface to this featurizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Load the featurizer</span>
<span class="kn">from</span> <span class="nn">grama.tran</span> <span class="kn">import</span> <span class="n">tf_feat_composition</span>
</pre></div>
</div>
</div>
</div>
<p>And the following code applies the featurizer to our chemical formula column.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit; featurize with the &quot;magpie&quot; featurizer</span>
<span class="n">df_fatigue_magpie</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_data</span>
    <span class="o">&gt;&gt;</span> <span class="n">tf_feat_composition</span><span class="p">(</span><span class="n">var_formula</span><span class="o">=</span><span class="s2">&quot;chemical_formula&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="p">(</span>
    <span class="n">df_fatigue_magpie</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_select</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;Magpie&quot;</span><span class="p">),</span> <span class="n">gr</span><span class="o">.</span><span class="n">everything</span><span class="p">())</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>StrToComposition:   0%|          | 0/437 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ElementProperty:   0%|          | 0/437 [00:00&lt;?, ?it/s]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MagpieData minimum Number</th>
      <th>MagpieData maximum Number</th>
      <th>MagpieData range Number</th>
      <th>MagpieData mean Number</th>
      <th>MagpieData avg_dev Number</th>
      <th>MagpieData mode Number</th>
      <th>MagpieData minimum MendeleevNumber</th>
      <th>MagpieData maximum MendeleevNumber</th>
      <th>MagpieData range MendeleevNumber</th>
      <th>MagpieData mean MendeleevNumber</th>
      <th>MagpieData avg_dev MendeleevNumber</th>
      <th>MagpieData mode MendeleevNumber</th>
      <th>MagpieData minimum AtomicWeight</th>
      <th>MagpieData maximum AtomicWeight</th>
      <th>MagpieData range AtomicWeight</th>
      <th>MagpieData mean AtomicWeight</th>
      <th>MagpieData avg_dev AtomicWeight</th>
      <th>MagpieData mode AtomicWeight</th>
      <th>MagpieData minimum MeltingT</th>
      <th>MagpieData maximum MeltingT</th>
      <th>MagpieData range MeltingT</th>
      <th>MagpieData mean MeltingT</th>
      <th>MagpieData avg_dev MeltingT</th>
      <th>MagpieData mode MeltingT</th>
      <th>MagpieData minimum Column</th>
      <th>MagpieData maximum Column</th>
      <th>MagpieData range Column</th>
      <th>MagpieData mean Column</th>
      <th>MagpieData avg_dev Column</th>
      <th>MagpieData mode Column</th>
      <th>MagpieData minimum Row</th>
      <th>MagpieData maximum Row</th>
      <th>MagpieData range Row</th>
      <th>MagpieData mean Row</th>
      <th>MagpieData avg_dev Row</th>
      <th>MagpieData mode Row</th>
      <th>MagpieData minimum CovalentRadius</th>
      <th>MagpieData maximum CovalentRadius</th>
      <th>MagpieData range CovalentRadius</th>
      <th>MagpieData mean CovalentRadius</th>
      <th>MagpieData avg_dev CovalentRadius</th>
      <th>MagpieData mode CovalentRadius</th>
      <th>MagpieData minimum Electronegativity</th>
      <th>MagpieData maximum Electronegativity</th>
      <th>MagpieData range Electronegativity</th>
      <th>MagpieData mean Electronegativity</th>
      <th>MagpieData avg_dev Electronegativity</th>
      <th>MagpieData mode Electronegativity</th>
      <th>MagpieData minimum NsValence</th>
      <th>MagpieData maximum NsValence</th>
      <th>MagpieData range NsValence</th>
      <th>MagpieData mean NsValence</th>
      <th>MagpieData avg_dev NsValence</th>
      <th>MagpieData mode NsValence</th>
      <th>MagpieData minimum NpValence</th>
      <th>MagpieData maximum NpValence</th>
      <th>MagpieData range NpValence</th>
      <th>MagpieData mean NpValence</th>
      <th>MagpieData avg_dev NpValence</th>
      <th>MagpieData mode NpValence</th>
      <th>MagpieData minimum NdValence</th>
      <th>MagpieData maximum NdValence</th>
      <th>MagpieData range NdValence</th>
      <th>MagpieData mean NdValence</th>
      <th>MagpieData avg_dev NdValence</th>
      <th>MagpieData mode NdValence</th>
      <th>MagpieData minimum NfValence</th>
      <th>MagpieData maximum NfValence</th>
      <th>MagpieData range NfValence</th>
      <th>MagpieData mean NfValence</th>
      <th>MagpieData avg_dev NfValence</th>
      <th>MagpieData mode NfValence</th>
      <th>MagpieData minimum NValence</th>
      <th>MagpieData maximum NValence</th>
      <th>MagpieData range NValence</th>
      <th>MagpieData mean NValence</th>
      <th>MagpieData avg_dev NValence</th>
      <th>MagpieData mode NValence</th>
      <th>MagpieData minimum NsUnfilled</th>
      <th>MagpieData maximum NsUnfilled</th>
      <th>MagpieData range NsUnfilled</th>
      <th>MagpieData mean NsUnfilled</th>
      <th>MagpieData avg_dev NsUnfilled</th>
      <th>MagpieData mode NsUnfilled</th>
      <th>MagpieData minimum NpUnfilled</th>
      <th>MagpieData maximum NpUnfilled</th>
      <th>MagpieData range NpUnfilled</th>
      <th>MagpieData mean NpUnfilled</th>
      <th>MagpieData avg_dev NpUnfilled</th>
      <th>MagpieData mode NpUnfilled</th>
      <th>MagpieData minimum NdUnfilled</th>
      <th>MagpieData maximum NdUnfilled</th>
      <th>MagpieData range NdUnfilled</th>
      <th>MagpieData mean NdUnfilled</th>
      <th>MagpieData avg_dev NdUnfilled</th>
      <th>MagpieData mode NdUnfilled</th>
      <th>MagpieData minimum NfUnfilled</th>
      <th>MagpieData maximum NfUnfilled</th>
      <th>MagpieData range NfUnfilled</th>
      <th>MagpieData mean NfUnfilled</th>
      <th>MagpieData avg_dev NfUnfilled</th>
      <th>MagpieData mode NfUnfilled</th>
      <th>MagpieData minimum NUnfilled</th>
      <th>MagpieData maximum NUnfilled</th>
      <th>MagpieData range NUnfilled</th>
      <th>MagpieData mean NUnfilled</th>
      <th>MagpieData avg_dev NUnfilled</th>
      <th>MagpieData mode NUnfilled</th>
      <th>MagpieData minimum GSvolume_pa</th>
      <th>MagpieData maximum GSvolume_pa</th>
      <th>MagpieData range GSvolume_pa</th>
      <th>MagpieData mean GSvolume_pa</th>
      <th>MagpieData avg_dev GSvolume_pa</th>
      <th>MagpieData mode GSvolume_pa</th>
      <th>MagpieData minimum GSbandgap</th>
      <th>MagpieData maximum GSbandgap</th>
      <th>MagpieData range GSbandgap</th>
      <th>MagpieData mean GSbandgap</th>
      <th>MagpieData avg_dev GSbandgap</th>
      <th>MagpieData mode GSbandgap</th>
      <th>MagpieData minimum GSmagmom</th>
      <th>MagpieData maximum GSmagmom</th>
      <th>MagpieData range GSmagmom</th>
      <th>MagpieData mean GSmagmom</th>
      <th>MagpieData avg_dev GSmagmom</th>
      <th>MagpieData mode GSmagmom</th>
      <th>MagpieData minimum SpaceGroupNumber</th>
      <th>MagpieData maximum SpaceGroupNumber</th>
      <th>MagpieData range SpaceGroupNumber</th>
      <th>MagpieData mean SpaceGroupNumber</th>
      <th>MagpieData avg_dev SpaceGroupNumber</th>
      <th>MagpieData mode SpaceGroupNumber</th>
      <th>Fatigue Strength</th>
      <th>chemical_formula</th>
      <th>Area Proportion of Inclusions Occurring in Discontinuous Array</th>
      <th>Quenching Media Temperature (for Carburization)</th>
      <th>Diffusion time</th>
      <th>Through Hardening Time</th>
      <th>Cooling Rate for Tempering</th>
      <th>Reduction Ratio (Ingot to Bar)</th>
      <th>Normalizing Temperature</th>
      <th>Diffusion Temperature</th>
      <th>Carburization Time</th>
      <th>Cooling Rate for Through Hardening</th>
      <th>Area Proportion of Inclusions Deformed by Plastic Work</th>
      <th>Tempering Temperature</th>
      <th>Area Proportion of Isolated Inclusions</th>
      <th>Tempering Time</th>
      <th>Carburization Temperature</th>
      <th>Through Hardening Temperature</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>25.87579</td>
      <td>0.248106</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.10385</td>
      <td>0.310521</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>63.5460</td>
      <td>51.5353</td>
      <td>55.589285</td>
      <td>0.510786</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1813.841076</td>
      <td>16.732357</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.02479</td>
      <td>0.084003</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.98950</td>
      <td>0.020863</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>139.0</td>
      <td>63.0</td>
      <td>131.83262</td>
      <td>0.563383</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.828778</td>
      <td>0.009002</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9986</td>
      <td>0.002796</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01349</td>
      <td>0.026805</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94770</td>
      <td>0.108594</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.95979</td>
      <td>0.083970</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0014</td>
      <td>0.002796</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02551</td>
      <td>0.050688</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.98730</td>
      <td>0.058207</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.01421</td>
      <td>0.034331</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.731722</td>
      <td>0.052205</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.020282</td>
      <td>0.040300</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.060158</td>
      <td>0.098575</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.60882</td>
      <td>0.764209</td>
      <td>229.0</td>
      <td>451.0</td>
      <td>Fe0.9759C0.004Mn0.0156Cu0.0005Si0.0022P0.00011...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>530.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.02</td>
      <td>550.0</td>
      <td>0.01</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>6.0</td>
      <td>42.0</td>
      <td>36.0</td>
      <td>25.89566</td>
      <td>0.276888</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.09326</td>
      <td>0.362195</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>95.9600</td>
      <td>83.9493</td>
      <td>55.633207</td>
      <td>0.586942</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1820.812713</td>
      <td>26.784568</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.01982</td>
      <td>0.099631</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>3.99088</td>
      <td>0.021714</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>154.0</td>
      <td>78.0</td>
      <td>131.85184</td>
      <td>0.610758</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.830467</td>
      <td>0.008331</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9876</td>
      <td>0.024492</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01454</td>
      <td>0.028879</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94848</td>
      <td>0.117990</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.95062</td>
      <td>0.111820</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0124</td>
      <td>0.024492</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02698</td>
      <td>0.053587</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.98232</td>
      <td>0.072595</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.02170</td>
      <td>0.059584</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.750695</td>
      <td>0.087031</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.020761</td>
      <td>0.041234</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.050632</td>
      <td>0.116566</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.67630</td>
      <td>0.635928</td>
      <td>229.0</td>
      <td>631.0</td>
      <td>Fe0.97088C0.004Mn0.0074Cu0.001Si0.0025P0.00014...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>510.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.04</td>
      <td>550.0</td>
      <td>0.03</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>6.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>25.87518</td>
      <td>0.249268</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>83.0</td>
      <td>34.0</td>
      <td>55.10376</td>
      <td>0.312739</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>63.5460</td>
      <td>51.5353</td>
      <td>55.587950</td>
      <td>0.514704</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1813.830695</td>
      <td>16.221727</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>15.0</td>
      <td>9.0</td>
      <td>8.02474</td>
      <td>0.084703</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.98958</td>
      <td>0.020702</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>139.0</td>
      <td>63.0</td>
      <td>131.84060</td>
      <td>0.547594</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.55</td>
      <td>1.00</td>
      <td>1.828564</td>
      <td>0.008907</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9980</td>
      <td>0.003992</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>0.01336</td>
      <td>0.026543</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94718</td>
      <td>0.109998</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.95854</td>
      <td>0.086403</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0020</td>
      <td>0.003992</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02636</td>
      <td>0.052371</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.98662</td>
      <td>0.059556</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.01498</td>
      <td>0.035106</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>22.570238</td>
      <td>16.930238</td>
      <td>10.735324</td>
      <td>0.056896</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.019367</td>
      <td>0.038477</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.059937</td>
      <td>0.099005</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.64796</td>
      <td>0.688013</td>
      <td>229.0</td>
      <td>406.0</td>
      <td>Fe0.97588C0.0038Mn0.0152Cu0.0007Si0.0027P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>610.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.03</td>
      <td>600.0</td>
      <td>0.01</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>6.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>25.88695</td>
      <td>0.224969</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.12760</td>
      <td>0.299052</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>63.5460</td>
      <td>51.5353</td>
      <td>55.602514</td>
      <td>0.482476</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1815.502371</td>
      <td>15.001282</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.03265</td>
      <td>0.080053</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.98985</td>
      <td>0.020169</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>139.0</td>
      <td>63.0</td>
      <td>131.78345</td>
      <td>0.533820</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.831016</td>
      <td>0.006118</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9996</td>
      <td>0.000800</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01345</td>
      <td>0.026726</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.95510</td>
      <td>0.090956</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.96815</td>
      <td>0.064818</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0004</td>
      <td>0.000800</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02525</td>
      <td>0.050174</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.98040</td>
      <td>0.053731</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.00605</td>
      <td>0.015110</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.737591</td>
      <td>0.056455</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.019175</td>
      <td>0.038102</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.080707</td>
      <td>0.059058</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.71185</td>
      <td>0.568203</td>
      <td>229.0</td>
      <td>433.0</td>
      <td>Fe0.98575C0.0037Mn0.0072Cu0.0002Si0.0024P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>1740.0</td>
      <td>865.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>24.0</td>
      <td>0.10</td>
      <td>550.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>865.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>6.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>25.87518</td>
      <td>0.249268</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>83.0</td>
      <td>34.0</td>
      <td>55.10376</td>
      <td>0.312739</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>63.5460</td>
      <td>51.5353</td>
      <td>55.587950</td>
      <td>0.514704</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1813.830695</td>
      <td>16.221727</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>15.0</td>
      <td>9.0</td>
      <td>8.02474</td>
      <td>0.084703</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.98958</td>
      <td>0.020702</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>139.0</td>
      <td>63.0</td>
      <td>131.84060</td>
      <td>0.547594</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.55</td>
      <td>1.00</td>
      <td>1.828564</td>
      <td>0.008907</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9980</td>
      <td>0.003992</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>0.01336</td>
      <td>0.026543</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94718</td>
      <td>0.109998</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.95854</td>
      <td>0.086403</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0020</td>
      <td>0.003992</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02636</td>
      <td>0.052371</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.98662</td>
      <td>0.059556</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.01498</td>
      <td>0.035106</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>22.570238</td>
      <td>16.930238</td>
      <td>10.735324</td>
      <td>0.056896</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.019367</td>
      <td>0.038477</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.059937</td>
      <td>0.099005</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.64796</td>
      <td>0.688013</td>
      <td>229.0</td>
      <td>385.0</td>
      <td>Fe0.97588C0.0038Mn0.0152Cu0.0007Si0.0027P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>610.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.03</td>
      <td>650.0</td>
      <td>0.01</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>432</th>
      <td>6.0</td>
      <td>42.0</td>
      <td>36.0</td>
      <td>25.89156</td>
      <td>0.280038</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.06447</td>
      <td>0.321348</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>95.9600</td>
      <td>83.9493</td>
      <td>55.629046</td>
      <td>0.591512</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1822.102271</td>
      <td>28.290384</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.01058</td>
      <td>0.086797</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>3.99111</td>
      <td>0.021659</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>154.0</td>
      <td>78.0</td>
      <td>131.88135</td>
      <td>0.579794</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.830052</td>
      <td>0.008019</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9869</td>
      <td>0.025857</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01402</td>
      <td>0.027850</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94176</td>
      <td>0.118925</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.94268</td>
      <td>0.116134</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0131</td>
      <td>0.025857</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02672</td>
      <td>0.053077</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.99034</td>
      <td>0.059771</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.03016</td>
      <td>0.064576</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.749287</td>
      <td>0.083763</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.020847</td>
      <td>0.041410</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.051826</td>
      <td>0.114380</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.70007</td>
      <td>0.590628</td>
      <td>229.0</td>
      <td>490.0</td>
      <td>Fe0.97201C0.0041Mn0.0077Cu0.0005Si0.0024P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>530.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.03</td>
      <td>650.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
    <tr>
      <th>433</th>
      <td>6.0</td>
      <td>28.0</td>
      <td>22.0</td>
      <td>25.86006</td>
      <td>0.276129</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.14978</td>
      <td>0.354176</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>58.6934</td>
      <td>46.6827</td>
      <td>55.543915</td>
      <td>0.593519</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1817.838531</td>
      <td>19.973873</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.03814</td>
      <td>0.094673</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.98744</td>
      <td>0.024925</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>139.0</td>
      <td>63.0</td>
      <td>131.72466</td>
      <td>0.665297</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.831628</td>
      <td>0.007771</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9990</td>
      <td>0.001998</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01620</td>
      <td>0.032149</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>5.94534</td>
      <td>0.108342</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>10.0</td>
      <td>6.0</td>
      <td>7.96054</td>
      <td>0.078437</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0010</td>
      <td>0.001998</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.03036</td>
      <td>0.060249</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.97706</td>
      <td>0.062515</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>4.00842</td>
      <td>0.018857</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.734557</td>
      <td>0.061742</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.024388</td>
      <td>0.048397</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.076043</td>
      <td>0.068101</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.64674</td>
      <td>0.695597</td>
      <td>229.0</td>
      <td>463.0</td>
      <td>Fe0.98354C0.0048Mn0.0075Si0.0025P0.00024S0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>1740.0</td>
      <td>845.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>24.0</td>
      <td>0.08</td>
      <td>600.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>845.0</td>
    </tr>
    <tr>
      <th>434</th>
      <td>6.0</td>
      <td>42.0</td>
      <td>36.0</td>
      <td>25.89454</td>
      <td>0.258376</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.06052</td>
      <td>0.298236</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>95.9600</td>
      <td>83.9493</td>
      <td>55.632321</td>
      <td>0.546836</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1820.378917</td>
      <td>24.652757</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.00966</td>
      <td>0.079592</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>3.99166</td>
      <td>0.019773</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>154.0</td>
      <td>78.0</td>
      <td>131.89434</td>
      <td>0.518359</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.829806</td>
      <td>0.007313</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9882</td>
      <td>0.023322</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01350</td>
      <td>0.026826</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94356</td>
      <td>0.111653</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.94526</td>
      <td>0.107939</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0118</td>
      <td>0.023322</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02514</td>
      <td>0.049956</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.99204</td>
      <td>0.053014</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.02898</td>
      <td>0.059322</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.753156</td>
      <td>0.084653</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.018487</td>
      <td>0.036737</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.057392</td>
      <td>0.103853</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.70006</td>
      <td>0.591698</td>
      <td>229.0</td>
      <td>592.0</td>
      <td>Fe0.97476C0.0035Mn0.007Cu0.0002Si0.0025P0.0002...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>820.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.10</td>
      <td>550.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
    <tr>
      <th>435</th>
      <td>6.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>25.91194</td>
      <td>0.176902</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.11106</td>
      <td>0.253827</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>63.5460</td>
      <td>51.5353</td>
      <td>55.654185</td>
      <td>0.383452</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1813.918083</td>
      <td>10.813308</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.02850</td>
      <td>0.067668</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>3.99208</td>
      <td>0.015756</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>139.0</td>
      <td>63.0</td>
      <td>131.82808</td>
      <td>0.411942</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.831007</td>
      <td>0.004691</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9992</td>
      <td>0.001599</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01142</td>
      <td>0.022718</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.96468</td>
      <td>0.073111</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.97530</td>
      <td>0.051490</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0008</td>
      <td>0.001599</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02050</td>
      <td>0.040782</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.98212</td>
      <td>0.045552</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.00342</td>
      <td>0.010966</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.744280</td>
      <td>0.057274</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.014385</td>
      <td>0.028617</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.087946</td>
      <td>0.044942</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.74824</td>
      <td>0.498324</td>
      <td>229.0</td>
      <td>245.0</td>
      <td>Fe0.98918C0.0026Mn0.0045Cu0.0003Si0.0022P0.000...</td>
      <td>0.02</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>825.0</td>
      <td>885.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.06</td>
      <td>30.0</td>
      <td>0.02</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>30.0</td>
    </tr>
    <tr>
      <th>436</th>
      <td>6.0</td>
      <td>42.0</td>
      <td>36.0</td>
      <td>25.89776</td>
      <td>0.257519</td>
      <td>26.0</td>
      <td>49.0</td>
      <td>88.0</td>
      <td>39.0</td>
      <td>55.06178</td>
      <td>0.306026</td>
      <td>55.0</td>
      <td>12.0107</td>
      <td>95.9600</td>
      <td>83.9493</td>
      <td>55.640955</td>
      <td>0.541728</td>
      <td>55.845</td>
      <td>317.3</td>
      <td>3823.0</td>
      <td>3505.7</td>
      <td>1820.055717</td>
      <td>24.991117</td>
      <td>1811.0</td>
      <td>6.0</td>
      <td>16.0</td>
      <td>10.0</td>
      <td>8.01044</td>
      <td>0.082922</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>3.99174</td>
      <td>0.019617</td>
      <td>4.0</td>
      <td>76.0</td>
      <td>154.0</td>
      <td>78.0</td>
      <td>131.89786</td>
      <td>0.525299</td>
      <td>132.0</td>
      <td>1.55</td>
      <td>2.58</td>
      <td>1.03</td>
      <td>1.829641</td>
      <td>0.007889</td>
      <td>1.83</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>1.9877</td>
      <td>0.024297</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.01310</td>
      <td>0.026036</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>10.0</td>
      <td>10.0</td>
      <td>5.94704</td>
      <td>0.111581</td>
      <td>6.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>11.0</td>
      <td>7.0</td>
      <td>7.94784</td>
      <td>0.108422</td>
      <td>8.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.0123</td>
      <td>0.024297</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>0.02446</td>
      <td>0.048614</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>3.99036</td>
      <td>0.058334</td>
      <td>4.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>4.02712</td>
      <td>0.061137</td>
      <td>4.0</td>
      <td>5.64</td>
      <td>25.786875</td>
      <td>20.146875</td>
      <td>10.749573</td>
      <td>0.079545</td>
      <td>10.73</td>
      <td>0.0</td>
      <td>4.496</td>
      <td>4.496</td>
      <td>0.018675</td>
      <td>0.037117</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>2.110663</td>
      <td>2.110663</td>
      <td>2.053637</td>
      <td>0.110953</td>
      <td>2.110663</td>
      <td>2.0</td>
      <td>229.0</td>
      <td>227.0</td>
      <td>228.70024</td>
      <td>0.590132</td>
      <td>229.0</td>
      <td>526.0</td>
      <td>Fe0.97284C0.0036Mn0.0081Cu0.0008Si0.0023P0.000...</td>
      <td>0.00</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>530.0</td>
      <td>870.0</td>
      <td>30.0</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>0.02</td>
      <td>550.0</td>
      <td>0.00</td>
      <td>60.0</td>
      <td>30.0</td>
      <td>855.0</td>
    </tr>
  </tbody>
</table>
<p>437 rows × 150 columns</p>
</div></div></div>
</div>
<p>Note that we now have over 100 new columns derived from the chemical formula. The following code picks feature columns by dropping the response column and string formula.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Obtain full feature set</span>
<span class="n">col_feat_both</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_magpie</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_drop</span><span class="p">(</span><span class="n">col_response</span><span class="p">,</span> <span class="s2">&quot;chemical_formula&quot;</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">columns</span>

<span class="n">col_feat_magpie</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_magpie</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_select</span><span class="p">(</span><span class="n">gr</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;Magpie&quot;</span><span class="p">))</span>
<span class="p">)</span><span class="o">.</span><span class="n">columns</span>

<span class="n">col_feat_magpie</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;MagpieData minimum Number&#39;, &#39;MagpieData maximum Number&#39;,
       &#39;MagpieData range Number&#39;, &#39;MagpieData mean Number&#39;,
       &#39;MagpieData avg_dev Number&#39;, &#39;MagpieData mode Number&#39;,
       &#39;MagpieData minimum MendeleevNumber&#39;,
       &#39;MagpieData maximum MendeleevNumber&#39;,
       &#39;MagpieData range MendeleevNumber&#39;, &#39;MagpieData mean MendeleevNumber&#39;,
       ...
       &#39;MagpieData range GSmagmom&#39;, &#39;MagpieData mean GSmagmom&#39;,
       &#39;MagpieData avg_dev GSmagmom&#39;, &#39;MagpieData mode GSmagmom&#39;,
       &#39;MagpieData minimum SpaceGroupNumber&#39;,
       &#39;MagpieData maximum SpaceGroupNumber&#39;,
       &#39;MagpieData range SpaceGroupNumber&#39;, &#39;MagpieData mean SpaceGroupNumber&#39;,
       &#39;MagpieData avg_dev SpaceGroupNumber&#39;,
       &#39;MagpieData mode SpaceGroupNumber&#39;],
      dtype=&#39;object&#39;, length=132)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="q6-interpret-the-following-results">
<h3><strong>Q6</strong>: Interpret the following results<a class="headerlink" href="#q6-interpret-the-following-results" title="Permalink to this headline">¶</a></h3>
<p>The following code estimates model accuracy both with and without the Magpie (composition) features. Compare the results and answer the questions under <em>Observations</em> below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## NOTE: No need to edit; run and answer the questions below</span>
<span class="n">df_err_processing</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_data</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_kfolds</span><span class="p">(</span>
        <span class="n">ft</span><span class="o">=</span><span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="n">col_processing</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">col_response</span><span class="p">),</span>
        <span class="n">summaries</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span>
        <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">feats</span><span class="o">=</span><span class="s2">&quot;processing only&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">df_err_magpie</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_magpie</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_kfolds</span><span class="p">(</span>
        <span class="n">ft</span><span class="o">=</span><span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="n">col_feat_magpie</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">col_response</span><span class="p">),</span>
        <span class="n">summaries</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span>
        <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">feats</span><span class="o">=</span><span class="s2">&quot;Magpie only&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">df_err_both</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df_fatigue_magpie</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_kfolds</span><span class="p">(</span>
        <span class="n">ft</span><span class="o">=</span><span class="n">ft_regression</span><span class="p">(</span><span class="n">var</span><span class="o">=</span><span class="n">col_feat_both</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">col_response</span><span class="p">),</span>
        <span class="n">summaries</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ndme</span><span class="o">=</span><span class="n">gr</span><span class="o">.</span><span class="n">ndme</span><span class="p">),</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">101</span><span class="p">,</span>
        <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_mutate</span><span class="p">(</span><span class="n">feats</span><span class="o">=</span><span class="s2">&quot;processing + Magpie&quot;</span><span class="p">)</span>
<span class="p">)</span>

<span class="p">(</span>
    <span class="n">df_err_processing</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_bind_rows</span><span class="p">(</span><span class="n">df_err_magpie</span><span class="p">)</span>
    <span class="o">&gt;&gt;</span> <span class="n">gr</span><span class="o">.</span><span class="n">tf_bind_rows</span><span class="p">(</span><span class="n">df_err_both</span><span class="p">)</span>
    
    <span class="o">&gt;&gt;</span> <span class="n">pt</span><span class="o">.</span><span class="n">ggplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="s2">&quot;feats&quot;</span><span class="p">,</span> <span class="s2">&quot;ndme_Fatigue Strength&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">geom_boxplot</span><span class="p">(</span><span class="n">pt</span><span class="o">.</span><span class="n">aes</span><span class="p">(</span><span class="n">group</span><span class="o">=</span><span class="s2">&quot;feats&quot;</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">pt</span><span class="o">.</span><span class="n">scale_y_continuous</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/05_ml_solution_69_0.png" src="../_images/05_ml_solution_69_0.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;ggplot: (8781495116633)&gt;
</pre></div>
</div>
</div>
</div>
<p><em>Observations</em>:</p>
<ul class="simple">
<li><p>Which feature set tends to produce a more accurate model?</p>
<ul>
<li><p>The <code class="docutils literal notranslate"><span class="pre">processing</span> <span class="pre">+</span> <span class="pre">Magpie</span></code> feature set tends to be the most accurate, but it also has more variable error than <code class="docutils literal notranslate"><span class="pre">processing</span> <span class="pre">only</span></code>. The <code class="docutils literal notranslate"><span class="pre">Magpie</span> <span class="pre">only</span></code> case is the least accurate.</p></li>
</ul>
</li>
<li><p>How large is the difference in accuracy between the cases?</p>
<ul>
<li><p>The difference between <code class="docutils literal notranslate"><span class="pre">processing</span> <span class="pre">+</span> <span class="pre">Magpie</span></code> and <code class="docutils literal notranslate"><span class="pre">processing</span> <span class="pre">only</span></code> is quite small. However <code class="docutils literal notranslate"><span class="pre">Magpie</span> <span class="pre">only</span></code> is quite separated from the other two.</p></li>
</ul>
</li>
<li><p>How important does the chemical composition (<em>as expressed by Magpie features</em>) tend to be in this case study?</p>
<ul>
<li><p>The chemical composition (<em>as expressed by Magpie features</em>) tends to be relatively unimportant.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h3>
<p>And that’s it! One could certainly take this case study further (<em>hint</em>: it would be interesting to see how different the alloys are in composition…), but hopefully this already gives you a sense for the kinds of investigations you can do in materials informatics.</p>
</div>
</div>
<div class="section" id="further-reading">
<h2>Further Reading<a class="headerlink" href="#further-reading" title="Permalink to this headline">¶</a></h2>
<hr class="docutils" />
<p>One of my favorite books on these ideas is <a class="reference external" href="https://www.statlearning.com/">An Introduction to Statistical Learning</a>. The authors have made PDF’s of the first and second editions <em>freely available</em>. This book does an excellent job of speaking to non-statisticians, while also not sacrificing statistical rigor. I highly recommend it!</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Zachary del Rosario<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>