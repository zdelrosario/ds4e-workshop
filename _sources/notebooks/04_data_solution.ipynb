{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0075c064",
   "metadata": {},
   "source": [
    "## Programmatic Data Operations\n",
    "\n",
    "*Authors: Zach del Rosario*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7955dd",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to give you some tools to work with data *programmatically*; that is, using a programming language. While you can carry out many data operations by hand or with spreadsheet programs, you will see that doing things programmatically is extremely powerful. \n",
    "\n",
    "### Learning Outcomes\n",
    "By working through this notebook, you will be able to:\n",
    "\n",
    "- Learn some basics of *data wrangling*\n",
    "- Use DataFrame operations from the package `py-grama`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ccf4f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import grama as gr\n",
    "\n",
    "DF = gr.Intention()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8cc9b",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce655b",
   "metadata": {},
   "source": [
    "A `DataFrame` is a data structure provided by Pandas. In contrast with `lists` (which we saw in the previous exercise), DataFrames are explicitly designed to facilitate data analysis. Accordingly, they provide a number of helpful features that aid in data analysis and operations.\n",
    "\n",
    "A `DataFrame` is a *rectangular* representation of data -- it consists of rows and columns. Each *row* represents an *observation* -- a single instance of data. Each *column* represents a *variable* -- a particular attribute of the observation. \n",
    "\n",
    "**TODO** (Update) For instance, we have loaded some alloy data into the DataFrame `df_data` -- here each row is an alloy, and each column is some physical property of that alloy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0de14a",
   "metadata": {},
   "source": [
    "### __Q1__: Inspecting a DataFrame\n",
    "Consult the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) (it might be useful to use a page search) and use some basic calls on `df_data` to answer the following questions:\n",
    "\n",
    "- What are the *last* five observations in the DataFrame?\n",
    "- How many rows are in `df_data`? How many columns?\n",
    "- How can you select the column \"Normalizing Temperature\"?\n",
    "- How can you select the columns \"Normalizing Temperature\" and \"Fatigue Strength\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f42ac75",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xv/k5cp232j1cn3y8kym53_nnkc0000gn/T/ipykernel_75937/1279774790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# -- WRITE YOUR CODE BELOW -----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# solution-begin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# solution-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_data' is not defined"
     ]
    }
   ],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Show the last five observations of df_data\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3d1b7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Determine the number of rows and columns in df_data\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data.shape  # rows, columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d77c3d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Select the column \"Normalizing Temperature\"\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data[[\"Normalizing Temperature\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806cb3c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Select the columns \"Normalizing Temperature\" and \"Fatigue Strength\"\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data[[\"Normalizing Temperature\", \"Fatigue Strength\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b1dd7",
   "metadata": {},
   "source": [
    "These manipulations are simple, but they are bread-and-butter for studying new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81013f",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6bc5a9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from grama.data import df_stang_wide\n",
    "df_stang_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08b537",
   "metadata": {},
   "source": [
    "Our goal will be to wrangle this messy, wide dataset into tidy, long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceeb6ef",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n",
    "df_stang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8cdf98",
   "metadata": {},
   "source": [
    "(What does pivoting look like? Here's an example.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98556d31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_tmp = (\n",
    "    gr.df_make(\n",
    "        A=[1, 2, 3],\n",
    "        B=[4, 5, 6],\n",
    "        C=[7, 8, 9],\n",
    "    )\n",
    ")\n",
    "print(df_tmp)\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"A\", \"B\", \"C\"],\n",
    "        names_to=\"name\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb1ede",
   "metadata": {},
   "source": [
    "### __QX__ \n",
    "\n",
    "(Make sure to add an `observation` column with the `index_to` argument.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68759083",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_qX = (\n",
    "    df_stang_wide\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"E_00\", \"mu_00\", \"E_45\", \"mu_45\", \"E_90\", \"mu_90\"],\n",
    "        names_to=\"name\",\n",
    "        values_to=\"value\",\n",
    "        index_to=\"observation\",\n",
    "    )\n",
    ")\n",
    "df_qX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ecb45b",
   "metadata": {},
   "source": [
    "Execute the following to check your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65176ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qX.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not sufficiently long; did you pivot?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qX.shape[1] == 5)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"observation\" in df_qX.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db1fe3",
   "metadata": {},
   "source": [
    "### __QY__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868a1ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_qY = (\n",
    "    df_qX\n",
    "    >> gr.tf_separate(\n",
    "        column=\"name\",\n",
    "        into=[\"var\", \"angle\"],\n",
    "        sep=\"_\",\n",
    "    )\n",
    ")\n",
    "df_qY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369b47b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54540ac8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qY.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qY.shape[1] == 6)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have six columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qY.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523285de",
   "metadata": {},
   "source": [
    "### __QZ__\n",
    "\n",
    "*Hint*: You should only need to set the `names_from` and `values_from` arguments with this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a7e3b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_qZ = (\n",
    "    df_qY\n",
    "    >> gr.tf_pivot_wider(\n",
    "        names_from=\"var\",\n",
    "        values_from=\"value\",\n",
    "    )\n",
    ")\n",
    "df_qZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f013af3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042fcda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qZ.shape[0] == 27)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"E\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'E' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"mu\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'mu' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1a7dc",
   "metadata": {},
   "source": [
    "### Bonus: One-step pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb4b5e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(\n",
    "    df_stang_wide\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"E_00\", \"mu_00\", \"E_45\", \"mu_45\", \"E_90\", \"mu_90\"],\n",
    "        names_to=[\".value\", \"angle\"],\n",
    "        names_sep=\"_\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8266a",
   "metadata": {},
   "source": [
    "## Wrangling Data\n",
    "[Hadley Wickham](http://hadley.nz/) -- author of the `tidyverse` and data science superstar -- notes that \"wrangling data is 80% boredom and 20% screaming\". To give you a sense of why this stuff is hard (but hopefully avoid the screaming), I'm leaving one of the wrangling steps in the workflow here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e14807b",
   "metadata": {},
   "source": [
    "It's not obvious from the exercises above, but *there's an issue with these data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346370a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfe472f",
   "metadata": {},
   "source": [
    "All of the entries are objects, not numbers! We'll need to convert these to numeric values. The following slightly-mysterious call will cast every column of `df_data` to a numeric type and modify the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac75603",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data = df_data.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e7e98",
   "metadata": {},
   "source": [
    "Let's check the data types again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e7870b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab07ea2",
   "metadata": {},
   "source": [
    "These are numbers we can work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c04081",
   "metadata": {},
   "source": [
    "## Basic DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569fbfd6",
   "metadata": {},
   "source": [
    "With the numerical issues above sorted out, we can carry out *quantitative* operations on the dataframe. One useful thing we can do is compute a set of *summaries* on the data using `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a148dc9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effa420b",
   "metadata": {},
   "source": [
    "These summaries include things like the `mean` and standard deviation (`std`), as well as quartiles of the data. These give us a sense of *typical* values; for instance, we can see that a large fraction of observations have a zero-\"Diffusion time\", but at least one observation has a value `> 70`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a5f433",
   "metadata": {},
   "source": [
    "### Special indexing\n",
    "One of the most powerful features of pandas is the ability to do *logical indexing*; we may provide an array of `True` or `False` values to select only those rows with `True` values. For instance, we could do the following to select the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9cdf3a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_boolean = [False] * df_data.shape[0]  # Mostly-false array\n",
    "idx_boolean[2] = True  # Make the third entry True\n",
    "df_data[idx_boolean]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f23d97",
   "metadata": {},
   "source": [
    "Where this kind of *logical indexing* becomes helpful is when we chain this with the conditionals we learned in the previous exercise. For instance, we could use logic *using one of the columns* to effectively \"filter\" for variables that meet some condition. For instance, the following will filter for nonzero \"Carburization Time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7aee52",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data[df_data[\"Carburization Time\"] > 0].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9642f",
   "metadata": {},
   "source": [
    "### Q5: Basic data operations\n",
    "Once more, use the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) to learn how to do the following tasks:\n",
    "\n",
    "- Select only those rows for which \"Diffusion time\" is greater than 70\n",
    "- Sort df_data in descending order by \"Fatigue Strength\" and return the top 10\n",
    "- Take the average of \"Normalizing Temperature\" and \"Tempering Temperature\" and add the column \"avg_temp\" (You may need to Google how to do this one!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96040b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Select rows for which \"Diffusion time\" > 70\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data[df_data[\"Diffusion time\"] > 70]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60af5e78",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Sort by \"Fatigue Strength\" in descending order, take the top-10\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data.sort_values(by=\"Fatigue Strength\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb9f17",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Average \"Normalizing Temperature\" and \"Tempering Temperature\" into the column \"avg_tmp\", return the head\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "df_data.assign(\n",
    "    avg_tmp=0.5 * (df_data[\"Normalizing Temperature\"] + df_data[\"Tempering Temperature\"])).head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
