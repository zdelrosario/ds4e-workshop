{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9b34843",
   "metadata": {},
   "source": [
    "## Programmatic Data Operations\n",
    "\n",
    "*Authors: Zach del Rosario*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a35fd4",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to give you some tools to work with data *programmatically*; that is, using a programming language. While you can carry out many data operations by hand or with spreadsheet programs, you will see that doing things programmatically is extremely powerful. \n",
    "\n",
    "### Learning Outcomes\n",
    "By working through this notebook, you will be able to:\n",
    "\n",
    "- Learn some basics of *data wrangling*\n",
    "- Use DataFrame operations from the package `py-grama`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f598790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import grama as gr\n",
    "\n",
    "DF = gr.Intention()\n",
    "\n",
    "# For downloading data\n",
    "import os\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d100f4b",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc716b6",
   "metadata": {},
   "source": [
    "A `DataFrame` is a data structure provided by Pandas. In contrast with `lists` (which we saw in the previous exercise), DataFrames are explicitly designed to facilitate data analysis. Accordingly, they provide a number of helpful features that aid in data analysis and operations.\n",
    "\n",
    "A `DataFrame` is a *rectangular* representation of data -- it consists of rows and columns. Each *row* represents an *observation* -- a single instance of data. Each *column* represents a *variable* -- a particular attribute of the observation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86903b27",
   "metadata": {},
   "source": [
    "For instance, the following code chunk downloads a alloy dataset into the DataFrame `df_mpea` -- here each row is an alloy, and each column is some physical property of that alloy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae3f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filename for local data\n",
    "filename_data = \"./data/mpea.csv\"\n",
    "\n",
    "# The following code downloads the data, or (after downloaded)\n",
    "# loads the data from a cached CSV on your machine\n",
    "if not os.path.exists(filename_data):\n",
    "    # Make request for data\n",
    "    url_data = \"https://docs.google.com/spreadsheets/u/1/d/1MsF4_jhWtEuZSvWfXLDHWEqLMScGCVXYWtqHW9Y7Yt0/export?format=csv\"\n",
    "    r = requests.get(url_data, allow_redirects=True)\n",
    "    open(filename_data, 'wb').write(r.content)\n",
    "    print(\"   MPEA data downloaded from public Google sheet\")\n",
    "else:\n",
    "    # Note data already exists\n",
    "    print(\"    MPEA data loaded locally\")\n",
    "    \n",
    "# Read the data into memory\n",
    "df_mpea = pd.read_csv(filename_data)\n",
    "\n",
    "# Check basic facts\n",
    "print(df_mpea.shape)\n",
    "df_mpea.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19176b8a",
   "metadata": {},
   "source": [
    "### __Q1__: Inspecting a DataFrame\n",
    "Consult the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) (it might be useful to use a page search) and use some basic calls on `df_data` to answer the following questions:\n",
    "\n",
    "- What are the *last* five observations in the DataFrame?\n",
    "- How many rows are in `df_data`? How many columns?\n",
    "- How would we access the column `PROPERTY: Microstructure`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04562414",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Show the last five observations of df_mpea\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa525099",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_mpea\n",
    "# TODO: Determine the number of rows and columns in df_mpea\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Grab the column `PROPERTY: Microstructure` alone\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec10a2",
   "metadata": {},
   "source": [
    "These manipulations are simple, but they are bread-and-butter for studying new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b7cc8c",
   "metadata": {},
   "source": [
    "## Grama\n",
    "\n",
    "---\n",
    "\n",
    "TODO the `py-grama` package builds on top of Pandas to provide a pipeline-based data (and model) infrastructure.\n",
    "\n",
    "Grama provides \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3b6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "   df_mpea\n",
    "   >> gr.tf_head()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401992b9",
   "metadata": {},
   "source": [
    "It's helpful to think of the `>>` symbol as meaning \"and then\". That means code like this:\n",
    "\n",
    "```\n",
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_filter( ... )\n",
    "    >> gr.tf_mutate( ... )\n",
    "    >> gr.tf_pivot_longer( ... )\n",
    ")\n",
    "```\n",
    "\n",
    "Can be read something like an English sentence, where we are using various *verbs* to operate on the data:\n",
    "\n",
    "```\n",
    "(\n",
    "    Start with df_mpea\n",
    "    and then filter the data\n",
    "    and then mutate the data\n",
    "    and then pivot the data in to a longer format\n",
    ")\n",
    "```\n",
    "\n",
    "We don't yet know what these verbs do; we'll learn more in the exercises below!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bdfbd1",
   "metadata": {},
   "source": [
    "### Selecting\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecadc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_select(\"FORMULA\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8c5ca",
   "metadata": {},
   "source": [
    "### __qX__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fe86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_select(\"FORMULA\", \"PROPERTY: Microstructure\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0af9d2",
   "metadata": {},
   "source": [
    "### __qX__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b35cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_select(gr.contains(\"REFERENCE\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab75325",
   "metadata": {},
   "source": [
    "### Renaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308aae0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_rename(\n",
    "        microstructure=\"PROPERTY: Microstructure\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69185205",
   "metadata": {},
   "source": [
    "## Interlude: Pipelines and the \"Data Pronoun\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071501b",
   "metadata": {},
   "source": [
    "(Illustrate the use of the data pronoun)\n",
    "\n",
    "Imagine we wanted to search through the dataset to find only those materials with a FCC microstructure. Above, we gave the `microstructure` column a new, convenient name. We might like to use that new, convenient name when searching for FCC materials. However, we're going to run into an issue:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611918ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Try uncommenting and running the following code; it WILL break!\n",
    "# (\n",
    "#     df_mpea\n",
    "#     >> gr.tf_rename(\n",
    "#         microstructure=\"PROPERTY: Microstructure\",\n",
    "#     )\n",
    "#     >> gr.tf_filter(\n",
    "#         df_mpea[\"microstructure\"] == \"FCC\"\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4eec51",
   "metadata": {},
   "source": [
    "If we want to refer to the data *now*---as it is currently in the pipeline---we need a name to refer to that DataFrame. This is where the *data pronoun* comes in; remember when we ran this line way up above in the setup chunk?\n",
    "\n",
    "```\n",
    "DF = gr.Intention()\n",
    "```\n",
    "\n",
    "This assigns the data pronoun to the name `DF`. We can use this to take advantage of the new (shorter) name we gave to the microstructure column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa305ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_rename(\n",
    "        microstructure=\"PROPERTY: Microstructure\",\n",
    "    )\n",
    "    >> gr.tf_filter(\n",
    "        DF[\"microstructure\"] == \"FCC\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12933d02",
   "metadata": {},
   "source": [
    "Together, the pipe operator `>>` and the data pronoun `DF` form a powerful team that helps us do sophisticated data operations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd99d5",
   "metadata": {},
   "source": [
    "### __qX__ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Eliminate the intermediate variables by using the data pronoun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c44d21",
   "metadata": {},
   "source": [
    "## Back to Verbs\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebefc6",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8e6545",
   "metadata": {},
   "source": [
    "### __qX__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c46c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original shape: {}\".format(df_mpea.shape))\n",
    "\n",
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_filter(gr.not_nan(DF[\"PROPERTY: YS (MPa)\"]))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d438de4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b734c3dd",
   "metadata": {},
   "source": [
    "### Mutating\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed741c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_mpea\n",
    "    >> gr.tf_mutate(\n",
    "        E_MPa = DF[\"PROPERTY: Young modulus (GPa)\"] * 1000\n",
    "    )\n",
    "    >> gr.tf_filter(gr.not_nan(DF.E_MPa))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50eade0",
   "metadata": {},
   "source": [
    "## Pivoting Data\n",
    "\n",
    "---\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae20dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang_wide\n",
    "df_stang_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563ec11c",
   "metadata": {},
   "source": [
    "Our goal will be to wrangle this messy, wide dataset into tidy, long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a27fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n",
    "df_stang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3b5b6",
   "metadata": {},
   "source": [
    "(What does pivoting look like? Here's an example.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173241ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = (\n",
    "    gr.df_make(\n",
    "        A=[1, 2, 3],\n",
    "        B=[4, 5, 6],\n",
    "        C=[7, 8, 9],\n",
    "    )\n",
    ")\n",
    "print(df_tmp)\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"A\", \"B\", \"C\"],\n",
    "        names_to=\"name\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a36238",
   "metadata": {},
   "source": [
    "### __QX__ \n",
    "\n",
    "(Make sure to add an `observation` column with the `index_to` argument.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cf8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_qX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b2aeb",
   "metadata": {},
   "source": [
    "Execute the following to check your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4741f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qX.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not sufficiently long; did you pivot?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qX.shape[1] == 5)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"observation\" in df_qX.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ac0c8",
   "metadata": {},
   "source": [
    "### __QY__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qY = (\n",
    "    df_qX\n",
    "\n",
    ")\n",
    "df_qY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c503dea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a4cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qY.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qY.shape[1] == 6)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have six columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qY.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2091c992",
   "metadata": {},
   "source": [
    "### __QZ__\n",
    "\n",
    "*Hint*: You should only need to set the `names_from` and `values_from` arguments with this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a8786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qZ = (\n",
    "    df_qY\n",
    "\n",
    ")\n",
    "df_qZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e54c05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qZ.shape[0] == 27)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"E\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'E' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"mu\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'mu' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df453a9",
   "metadata": {},
   "source": [
    "### Bonus: One-step pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78116cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_stang_wide\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"E_00\", \"mu_00\", \"E_45\", \"mu_45\", \"E_90\", \"mu_90\"],\n",
    "        names_to=[\".value\", \"angle\"],\n",
    "        names_sep=\"_\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc07ef1",
   "metadata": {},
   "source": [
    "## Wrangling Data\n",
    "[Hadley Wickham](http://hadley.nz/) -- author of the `tidyverse` and data science superstar -- notes that \"wrangling data is 80% boredom and 20% screaming\". To give you a sense of why this stuff is hard (but hopefully avoid the screaming), I'm leaving one of the wrangling steps in the workflow here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a1f6e",
   "metadata": {},
   "source": [
    "It's not obvious from the exercises above, but *there's an issue with these data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198d231",
   "metadata": {},
   "source": [
    "All of the entries are objects, not numbers! We'll need to convert these to numeric values. The following slightly-mysterious call will cast every column of `df_data` to a numeric type and modify the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c92c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd16022c",
   "metadata": {},
   "source": [
    "Let's check the data types again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d960a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec4a22",
   "metadata": {},
   "source": [
    "These are numbers we can work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883dd082",
   "metadata": {},
   "source": [
    "## Basic DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cf461",
   "metadata": {},
   "source": [
    "With the numerical issues above sorted out, we can carry out *quantitative* operations on the dataframe. One useful thing we can do is compute a set of *summaries* on the data using `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f290521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8aa232",
   "metadata": {},
   "source": [
    "These summaries include things like the `mean` and standard deviation (`std`), as well as quartiles of the data. These give us a sense of *typical* values; for instance, we can see that a large fraction of observations have a zero-\"Diffusion time\", but at least one observation has a value `> 70`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cc891",
   "metadata": {},
   "source": [
    "### Special indexing\n",
    "One of the most powerful features of pandas is the ability to do *logical indexing*; we may provide an array of `True` or `False` values to select only those rows with `True` values. For instance, we could do the following to select the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25828c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_boolean = [False] * df_data.shape[0]  # Mostly-false array\n",
    "idx_boolean[2] = True  # Make the third entry True\n",
    "df_data[idx_boolean]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a9b7de",
   "metadata": {},
   "source": [
    "Where this kind of *logical indexing* becomes helpful is when we chain this with the conditionals we learned in the previous exercise. For instance, we could use logic *using one of the columns* to effectively \"filter\" for variables that meet some condition. For instance, the following will filter for nonzero \"Carburization Time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[df_data[\"Carburization Time\"] > 0].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77798453",
   "metadata": {},
   "source": [
    "### Q5: Basic data operations\n",
    "Once more, use the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) to learn how to do the following tasks:\n",
    "\n",
    "- Select only those rows for which \"Diffusion time\" is greater than 70\n",
    "- Sort df_data in descending order by \"Fatigue Strength\" and return the top 10\n",
    "- Take the average of \"Normalizing Temperature\" and \"Tempering Temperature\" and add the column \"avg_temp\" (You may need to Google how to do this one!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Select rows for which \"Diffusion time\" > 70\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82dd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Sort by \"Fatigue Strength\" in descending order, take the top-10\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea390de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Average \"Normalizing Temperature\" and \"Tempering Temperature\" into the column \"avg_tmp\", return the head\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
