{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe961a4",
   "metadata": {},
   "source": [
    "## Programmatic Data Operations\n",
    "\n",
    "*Authors: Zach del Rosario*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0262b59",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to give you some tools to work with data *programmatically*; that is, using a programming language. While you can carry out many data operations by hand or with spreadsheet programs, you will see that doing things programmatically is extremely powerful. \n",
    "\n",
    "### Learning Outcomes\n",
    "By working through this notebook, you will be able to:\n",
    "\n",
    "- Learn some basics of *data wrangling*\n",
    "- Use DataFrame operations from the package `py-grama`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90424352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import grama as gr\n",
    "\n",
    "DF = gr.Intention()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adb87c1",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1d417d",
   "metadata": {},
   "source": [
    "A `DataFrame` is a data structure provided by Pandas. In contrast with `lists` (which we saw in the previous exercise), DataFrames are explicitly designed to facilitate data analysis. Accordingly, they provide a number of helpful features that aid in data analysis and operations.\n",
    "\n",
    "A `DataFrame` is a *rectangular* representation of data -- it consists of rows and columns. Each *row* represents an *observation* -- a single instance of data. Each *column* represents a *variable* -- a particular attribute of the observation. \n",
    "\n",
    "**TODO** (Update) For instance, we have loaded some alloy data into the DataFrame `df_data` -- here each row is an alloy, and each column is some physical property of that alloy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcfb15",
   "metadata": {},
   "source": [
    "### __Q1__: Inspecting a DataFrame\n",
    "Consult the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) (it might be useful to use a page search) and use some basic calls on `df_data` to answer the following questions:\n",
    "\n",
    "- What are the *last* five observations in the DataFrame?\n",
    "- How many rows are in `df_data`? How many columns?\n",
    "- How can you select the column \"Normalizing Temperature\"?\n",
    "- How can you select the columns \"Normalizing Temperature\" and \"Fatigue Strength\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Show the last five observations of df_data\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d21ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Determine the number of rows and columns in df_data\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Select the column \"Normalizing Temperature\"\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04842420",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Select the columns \"Normalizing Temperature\" and \"Fatigue Strength\"\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709289c5",
   "metadata": {},
   "source": [
    "These manipulations are simple, but they are bread-and-butter for studying new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d263f9a",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d20ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang_wide\n",
    "df_stang_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0012d2f9",
   "metadata": {},
   "source": [
    "Our goal will be to wrangle this messy, wide dataset into tidy, long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c61881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n",
    "df_stang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed0bd7",
   "metadata": {},
   "source": [
    "(What does pivoting look like? Here's an example.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73169ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = (\n",
    "    gr.df_make(\n",
    "        A=[1, 2, 3],\n",
    "        B=[4, 5, 6],\n",
    "        C=[7, 8, 9],\n",
    "    )\n",
    ")\n",
    "print(df_tmp)\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"A\", \"B\", \"C\"],\n",
    "        names_to=\"name\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e82a6",
   "metadata": {},
   "source": [
    "### __QX__ \n",
    "\n",
    "(Make sure to add an `observation` column with the `index_to` argument.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cb0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_qX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd53551",
   "metadata": {},
   "source": [
    "Execute the following to check your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e09b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qX.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not sufficiently long; did you pivot?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qX.shape[1] == 5)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"observation\" in df_qX.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0e08d",
   "metadata": {},
   "source": [
    "### __QY__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de79167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qY = (\n",
    "    df_qX\n",
    "\n",
    ")\n",
    "df_qY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75039a8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ce9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qY.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qY.shape[1] == 6)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have six columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qY.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680fc0a",
   "metadata": {},
   "source": [
    "### __QZ__\n",
    "\n",
    "*Hint*: You should only need to set the `names_from` and `values_from` arguments with this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7d29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qZ = (\n",
    "    df_qY\n",
    "\n",
    ")\n",
    "df_qZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8ba93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af7e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qZ.shape[0] == 27)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"E\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'E' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"mu\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'mu' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b33752",
   "metadata": {},
   "source": [
    "### Bonus: One-step pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f59bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_stang_wide\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"E_00\", \"mu_00\", \"E_45\", \"mu_45\", \"E_90\", \"mu_90\"],\n",
    "        names_to=[\".value\", \"angle\"],\n",
    "        names_sep=\"_\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf3037f",
   "metadata": {},
   "source": [
    "## Wrangling Data\n",
    "[Hadley Wickham](http://hadley.nz/) -- author of the `tidyverse` and data science superstar -- notes that \"wrangling data is 80% boredom and 20% screaming\". To give you a sense of why this stuff is hard (but hopefully avoid the screaming), I'm leaving one of the wrangling steps in the workflow here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881cafc7",
   "metadata": {},
   "source": [
    "It's not obvious from the exercises above, but *there's an issue with these data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ddb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da21a99d",
   "metadata": {},
   "source": [
    "All of the entries are objects, not numbers! We'll need to convert these to numeric values. The following slightly-mysterious call will cast every column of `df_data` to a numeric type and modify the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116f2a2",
   "metadata": {},
   "source": [
    "Let's check the data types again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc34d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f1ddc4",
   "metadata": {},
   "source": [
    "These are numbers we can work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a260544",
   "metadata": {},
   "source": [
    "## Basic DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ebb287",
   "metadata": {},
   "source": [
    "With the numerical issues above sorted out, we can carry out *quantitative* operations on the dataframe. One useful thing we can do is compute a set of *summaries* on the data using `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c9f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57894f",
   "metadata": {},
   "source": [
    "These summaries include things like the `mean` and standard deviation (`std`), as well as quartiles of the data. These give us a sense of *typical* values; for instance, we can see that a large fraction of observations have a zero-\"Diffusion time\", but at least one observation has a value `> 70`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950c87fb",
   "metadata": {},
   "source": [
    "### Special indexing\n",
    "One of the most powerful features of pandas is the ability to do *logical indexing*; we may provide an array of `True` or `False` values to select only those rows with `True` values. For instance, we could do the following to select the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63353a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_boolean = [False] * df_data.shape[0]  # Mostly-false array\n",
    "idx_boolean[2] = True  # Make the third entry True\n",
    "df_data[idx_boolean]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec5895",
   "metadata": {},
   "source": [
    "Where this kind of *logical indexing* becomes helpful is when we chain this with the conditionals we learned in the previous exercise. For instance, we could use logic *using one of the columns* to effectively \"filter\" for variables that meet some condition. For instance, the following will filter for nonzero \"Carburization Time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a313078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[df_data[\"Carburization Time\"] > 0].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b39b8e",
   "metadata": {},
   "source": [
    "### Q5: Basic data operations\n",
    "Once more, use the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) to learn how to do the following tasks:\n",
    "\n",
    "- Select only those rows for which \"Diffusion time\" is greater than 70\n",
    "- Sort df_data in descending order by \"Fatigue Strength\" and return the top 10\n",
    "- Take the average of \"Normalizing Temperature\" and \"Tempering Temperature\" and add the column \"avg_temp\" (You may need to Google how to do this one!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea89d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Select rows for which \"Diffusion time\" > 70\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9acb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Sort by \"Fatigue Strength\" in descending order, take the top-10\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a21e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Average \"Normalizing Temperature\" and \"Tempering Temperature\" into the column \"avg_tmp\", return the head\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
