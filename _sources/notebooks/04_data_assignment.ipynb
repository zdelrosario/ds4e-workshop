{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6192c618",
   "metadata": {},
   "source": [
    "## Programmatic Data Operations\n",
    "\n",
    "*Authors: Zach del Rosario*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53819e",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to give you some tools to work with data *programmatically*; that is, using a programming language. While you can carry out many data operations by hand or with spreadsheet programs, you will see that doing things programmatically is extremely powerful. \n",
    "\n",
    "### Learning Outcomes\n",
    "By working through this notebook, you will be able to:\n",
    "\n",
    "- Learn some basics of *data wrangling*\n",
    "- Use DataFrame operations from the package `py-grama`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import grama as gr\n",
    "\n",
    "DF = gr.Intention()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d394c",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a23dbb",
   "metadata": {},
   "source": [
    "A `DataFrame` is a data structure provided by Pandas. In contrast with `lists` (which we saw in the previous exercise), DataFrames are explicitly designed to facilitate data analysis. Accordingly, they provide a number of helpful features that aid in data analysis and operations.\n",
    "\n",
    "A `DataFrame` is a *rectangular* representation of data -- it consists of rows and columns. Each *row* represents an *observation* -- a single instance of data. Each *column* represents a *variable* -- a particular attribute of the observation. \n",
    "\n",
    "**TODO** (Update) For instance, we have loaded some alloy data into the DataFrame `df_data` -- here each row is an alloy, and each column is some physical property of that alloy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e2f3c",
   "metadata": {},
   "source": [
    "### __Q1__: Inspecting a DataFrame\n",
    "Consult the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) (it might be useful to use a page search) and use some basic calls on `df_data` to answer the following questions:\n",
    "\n",
    "- What are the *last* five observations in the DataFrame?\n",
    "- How many rows are in `df_data`? How many columns?\n",
    "- How can you select the column \"Normalizing Temperature\"?\n",
    "- How can you select the columns \"Normalizing Temperature\" and \"Fatigue Strength\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5545ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Show the last five observations of df_data\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae666a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Determine the number of rows and columns in df_data\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Select the column \"Normalizing Temperature\"\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239f93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Inspect df_data\n",
    "# TODO: Select the columns \"Normalizing Temperature\" and \"Fatigue Strength\"\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440aebc1",
   "metadata": {},
   "source": [
    "These manipulations are simple, but they are bread-and-butter for studying new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e45874",
   "metadata": {},
   "source": [
    "### Pivoting\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7612202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang_wide\n",
    "df_stang_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3efc02",
   "metadata": {},
   "source": [
    "Our goal will be to wrangle this messy, wide dataset into tidy, long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grama.data import df_stang\n",
    "df_stang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f792c2",
   "metadata": {},
   "source": [
    "(What does pivoting look like? Here's an example.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = (\n",
    "    gr.df_make(\n",
    "        A=[1, 2, 3],\n",
    "        B=[4, 5, 6],\n",
    "        C=[7, 8, 9],\n",
    "    )\n",
    ")\n",
    "print(df_tmp)\n",
    "\n",
    "(\n",
    "    df_tmp\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"A\", \"B\", \"C\"],\n",
    "        names_to=\"name\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17543def",
   "metadata": {},
   "source": [
    "### __QX__ \n",
    "\n",
    "(Make sure to add an `observation` column with the `index_to` argument.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cddb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_qX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdb77d7",
   "metadata": {},
   "source": [
    "Execute the following to check your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qX.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not sufficiently long; did you pivot?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qX.shape[1] == 5)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"observation\" in df_qX.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have five columns\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60335427",
   "metadata": {},
   "source": [
    "### __QY__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qY = (\n",
    "    df_qX\n",
    "\n",
    ")\n",
    "df_qY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdda60a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b0f5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qY.shape[0] == 54)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(df_qY.shape[1] == 6)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have six columns\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qY.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fab56d",
   "metadata": {},
   "source": [
    "### __QZ__\n",
    "\n",
    "*Hint*: You should only need to set the `names_from` and `values_from` arguments with this function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qZ = (\n",
    "    df_qY\n",
    "\n",
    ")\n",
    "df_qZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf0b290",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9169379",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert(df_qZ.shape[0] == 27)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame is not the right length; how did that happen?\")\n",
    "    \n",
    "try:\n",
    "    assert(\"angle\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'angle' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"E\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'E' column\")\n",
    "    \n",
    "try:\n",
    "    assert(\"mu\" in df_qZ.columns)\n",
    "except AssertionError:\n",
    "    raise AssertionError(\"The DataFrame should have an 'mu' column\")\n",
    "    \n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1029bd4",
   "metadata": {},
   "source": [
    "### Bonus: One-step pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db309a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df_stang_wide\n",
    "    >> gr.tf_pivot_longer(\n",
    "        columns=[\"E_00\", \"mu_00\", \"E_45\", \"mu_45\", \"E_90\", \"mu_90\"],\n",
    "        names_to=[\".value\", \"angle\"],\n",
    "        names_sep=\"_\",\n",
    "        values_to=\"value\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948eae5",
   "metadata": {},
   "source": [
    "## Wrangling Data\n",
    "[Hadley Wickham](http://hadley.nz/) -- author of the `tidyverse` and data science superstar -- notes that \"wrangling data is 80% boredom and 20% screaming\". To give you a sense of why this stuff is hard (but hopefully avoid the screaming), I'm leaving one of the wrangling steps in the workflow here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58336603",
   "metadata": {},
   "source": [
    "It's not obvious from the exercises above, but *there's an issue with these data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4277b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6546c",
   "metadata": {},
   "source": [
    "All of the entries are objects, not numbers! We'll need to convert these to numeric values. The following slightly-mysterious call will cast every column of `df_data` to a numeric type and modify the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd8c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e00993",
   "metadata": {},
   "source": [
    "Let's check the data types again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91616055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8fae83",
   "metadata": {},
   "source": [
    "These are numbers we can work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c74a35",
   "metadata": {},
   "source": [
    "## Basic DataFrame Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36beb7",
   "metadata": {},
   "source": [
    "With the numerical issues above sorted out, we can carry out *quantitative* operations on the dataframe. One useful thing we can do is compute a set of *summaries* on the data using `describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47082fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a8162",
   "metadata": {},
   "source": [
    "These summaries include things like the `mean` and standard deviation (`std`), as well as quartiles of the data. These give us a sense of *typical* values; for instance, we can see that a large fraction of observations have a zero-\"Diffusion time\", but at least one observation has a value `> 70`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56dfd67",
   "metadata": {},
   "source": [
    "### Special indexing\n",
    "One of the most powerful features of pandas is the ability to do *logical indexing*; we may provide an array of `True` or `False` values to select only those rows with `True` values. For instance, we could do the following to select the third row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_boolean = [False] * df_data.shape[0]  # Mostly-false array\n",
    "idx_boolean[2] = True  # Make the third entry True\n",
    "df_data[idx_boolean]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb5fa8d",
   "metadata": {},
   "source": [
    "Where this kind of *logical indexing* becomes helpful is when we chain this with the conditionals we learned in the previous exercise. For instance, we could use logic *using one of the columns* to effectively \"filter\" for variables that meet some condition. For instance, the following will filter for nonzero \"Carburization Time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c8797",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data[df_data[\"Carburization Time\"] > 0].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45d363",
   "metadata": {},
   "source": [
    "### Q5: Basic data operations\n",
    "Once more, use the [pandas documentation](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html) to learn how to do the following tasks:\n",
    "\n",
    "- Select only those rows for which \"Diffusion time\" is greater than 70\n",
    "- Sort df_data in descending order by \"Fatigue Strength\" and return the top 10\n",
    "- Take the average of \"Normalizing Temperature\" and \"Tempering Temperature\" and add the column \"avg_temp\" (You may need to Google how to do this one!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d93566",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Select rows for which \"Diffusion time\" > 70\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48927361",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Sort by \"Fatigue Strength\" in descending order, take the top-10\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb56a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# TASK: Basic data operations\n",
    "# TODO: Average \"Normalizing Temperature\" and \"Tempering Temperature\" into the column \"avg_tmp\", return the head\n",
    "###\n",
    "\n",
    "# -- WRITE YOUR CODE BELOW -----\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
